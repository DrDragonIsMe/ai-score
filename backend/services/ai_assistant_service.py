#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
AIæ™ºèƒ½å­¦ä¹ ç³»ç»Ÿ - ä¸šåŠ¡æœåŠ¡ - ai_assistant_service.py

Description:
    AIåŠ©ç†"é«˜å°åˆ†"æœåŠ¡ï¼Œæä¾›æ™ºèƒ½å¯¹è¯ã€æ‹ç…§è¯†åˆ«è¯•é¢˜ã€ä¸ªæ€§åŒ–å­¦ä¹ å»ºè®®ç­‰åŠŸèƒ½ã€‚

Author: Chang Xinglong
Date: 2025-01-21
Version: 1.0.0
License: Apache License 2.0
"""

import json
import base64
import requests
from datetime import datetime
from typing import Dict, List, Any, Optional
from PIL import Image
import io
import pytesseract
from utils.database import db
from models.user import User
from models.diagnosis import DiagnosisReport, WeaknessPoint
from models.knowledge import KnowledgePoint, Subject
from models.exam import ExamSession, ExamAnalytics
from models.exam_papers import ExamPaper
from models.mistake import MistakeRecord, MistakeReviewSession, MistakePattern
from models.learning import StudyRecord, MemoryCard
from services.llm_service import llm_service
from services.diagnosis_service import DiagnosisService
from services.document_service import get_document_service
from services.vector_database_service import vector_db_service
from services.ppt_generation_service import ppt_generation_service
from utils.logger import get_logger

logger = get_logger(__name__)

class AIAssistantService:
    """
    AIåŠ©ç†"é«˜å°åˆ†"æœåŠ¡ç±»
    """
    
    def __init__(self):
        self.assistant_name = "é«˜å°åˆ†"
        self.assistant_personality = {
            "role": "æ™ºèƒ½å­¦ä¹ åŠ©æ‰‹",
            "traits": ["å‹å–„", "è€å¿ƒ", "ä¸“ä¸š", "é¼“åŠ±æ€§"],
            "greeting": "ä½ å¥½ï¼æˆ‘æ˜¯é«˜å°åˆ†ï¼Œä½ çš„ä¸“å±å­¦ä¹ åŠ©æ‰‹ã€‚æˆ‘å¯ä»¥å¸®ä½ åˆ†æè¯•é¢˜ã€åˆ¶å®šå­¦ä¹ è®¡åˆ’ï¼Œè¿˜èƒ½é€šè¿‡æ‹ç…§è¯†åˆ«é¢˜ç›®å“¦ï¼"
        }
    
    def get_assistant_info(self) -> Dict[str, Any]:
        """
        è·å–AIåŠ©ç†åŸºæœ¬ä¿¡æ¯
        """
        return {
            "name": self.assistant_name,
            "personality": self.assistant_personality,
            "capabilities": [
                "æ™ºèƒ½å¯¹è¯äº¤æµ",
                "æ‹ç…§è¯†åˆ«è¯•é¢˜",
                "è¯•é¢˜åˆ†æè§£ç­”",
                "ä¸ªæ€§åŒ–å­¦ä¹ å»ºè®®",
                "å­¦ä¹ è¿›åº¦è·Ÿè¸ª",
                "çŸ¥è¯†ç‚¹æ¨è",
                "PDFæ–‡æ¡£åˆ†æ",
                "æ–‡æ¡£å†…å®¹é—®ç­”"
            ]
        }
    
    def chat_with_user(self, user_id: str, message: str, context: Optional[Dict] = None, 
                      model_id: Optional[str] = None, template_id: Optional[str] = None) -> Dict[str, Any]:
        """
        ä¸ç”¨æˆ·è¿›è¡Œæ™ºèƒ½å¯¹è¯
        
        Args:
            user_id: ç”¨æˆ·ID
            message: ç”¨æˆ·æ¶ˆæ¯
            context: å¯¹è¯ä¸Šä¸‹æ–‡
            model_id: æŒ‡å®šä½¿ç”¨çš„AIæ¨¡å‹ID
            template_id: PPTæ¨¡æ¿IDï¼ˆç”¨äºPPTç”Ÿæˆï¼‰
        
        Returns:
            AIåŠ©ç†å›å¤
        """
        try:
            # æ£€æµ‹æ˜¯å¦éœ€è¦ç”ŸæˆPPT
            if self._should_generate_ppt(message):
                return self._handle_ppt_generation(user_id, message, template_id)
            
            # è·å–ç”¨æˆ·ä¿¡æ¯å’Œå­¦ä¹ æƒ…å†µ
            user_profile = self._get_user_learning_profile(user_id)
            
            # æ£€ç´¢ç»¼åˆæ•°æ®ï¼ˆæ–‡æ¡£ã€è¯•å·ã€é”™é¢˜è®°å½•ç­‰ï¼‰
            comprehensive_data = self._retrieve_comprehensive_data(user_id, message)
            
            # æ„å»ºå¯¹è¯æç¤ºè¯ï¼ˆåŒ…å«ç»¼åˆæ•°æ®ä¿¡æ¯ï¼‰
            system_prompt = self._build_comprehensive_chat_prompt(user_profile, context, comprehensive_data)
            
            # è°ƒç”¨å¤§æ¨¡å‹ç”Ÿæˆå›å¤
            full_prompt = f"{system_prompt}\n\nç”¨æˆ·: {message}\n\né«˜å°åˆ†:"
            
            response = llm_service.generate_text(
                prompt=full_prompt,
                max_tokens=500,
                temperature=0.7,
                model_name=model_id
            )
            
            return {
                "success": True,
                "response": response,
                "assistant_name": self.assistant_name,
                "model_used": model_id or "default",
                "timestamp": datetime.now().isoformat(),
                "suggestions": self._generate_contextual_suggestions(user_id, message),
                "referenced_data": comprehensive_data
            }
            
        except Exception as e:
            logger.error(f"AIåŠ©ç†å¯¹è¯å¤±è´¥: {str(e)}")
            return {
                "success": False,
                "response": "æŠ±æ­‰ï¼Œæˆ‘ç°åœ¨æœ‰ç‚¹å¿™ï¼Œè¯·ç¨åå†è¯•ã€‚",
                "error": str(e)
            }
    
    def recognize_question_from_image(self, user_id: str, image_data: str) -> Dict[str, Any]:
        """
        ä»å›¾ç‰‡ä¸­è¯†åˆ«è¯•é¢˜æˆ–æè¿°å›¾ç‰‡å†…å®¹
        
        Args:
            user_id: ç”¨æˆ·ID
            image_data: Base64ç¼–ç çš„å›¾ç‰‡æ•°æ®
        
        Returns:
            è¯†åˆ«ç»“æœ
        """
        try:
            # è§£ç å›¾ç‰‡
            image_bytes = base64.b64decode(image_data)
            image = Image.open(io.BytesIO(image_bytes))
            
            # OCRè¯†åˆ«æ–‡å­—
            extracted_text = pytesseract.image_to_string(image, lang='chi_sim+eng')
            
            # å¦‚æœæ²¡æœ‰è¯†åˆ«åˆ°æ–‡å­—ï¼Œå°è¯•æè¿°å›¾ç‰‡å†…å®¹
            if not extracted_text.strip():
                image_description = self._describe_image_content(image_data, user_id)
                return {
                    "success": True,
                    "content_type": "image_description",
                    "description": image_description,
                    "message": "è¿™å¼ å›¾ç‰‡æ²¡æœ‰æ–‡å­—å†…å®¹ï¼Œæˆ‘æ¥ä¸ºä½ æè¿°ä¸€ä¸‹å›¾ç‰‡å†…å®¹ã€‚",
                    "timestamp": datetime.now().isoformat()
                }
            
            # ä½¿ç”¨AIåˆ†æè¯†åˆ«çš„æ–‡æœ¬ï¼Œåˆ¤æ–­æ˜¯å¦ä¸ºé¢˜ç›®
            content_analysis = self._analyze_extracted_text(extracted_text, user_id)
            
            logger.info(f"å›¾ç‰‡è¯†åˆ«æˆåŠŸ - æå–æ–‡æœ¬: {extracted_text[:100]}...")
            logger.info(f"å†…å®¹åˆ†æç»“æœ: {content_analysis}")
            
            # æ ¹æ®åˆ†æç»“æœå†³å®šå¤„ç†æ–¹å¼
            if content_analysis.get('is_question', False):
                return {
                    "success": True,
                    "content_type": "question",
                    "extracted_text": extracted_text,
                    "question_analysis": content_analysis,
                    "timestamp": datetime.now().isoformat()
                }
            else:
                # ä¸æ˜¯é¢˜ç›®ï¼Œæè¿°å›¾ç‰‡å†…å®¹
                image_description = self._describe_image_content(image_data, user_id, extracted_text)
                return {
                    "success": True,
                    "content_type": "image_description",
                    "extracted_text": extracted_text,
                    "description": image_description,
                    "message": "è¿™å¼ å›¾ç‰‡ä¸æ˜¯é¢˜ç›®ï¼Œæˆ‘æ¥ä¸ºä½ ä»‹ç»ä¸€ä¸‹å›¾ç‰‡å†…å®¹ã€‚",
                    "timestamp": datetime.now().isoformat()
                }
            
        except Exception as e:
            logger.error(f"å›¾ç‰‡è¯†åˆ«å¤±è´¥: {str(e)}")
            return {
                "success": False,
                "message": "å›¾ç‰‡è¯†åˆ«å¤±è´¥ï¼Œè¯·é‡è¯•ã€‚",
                "error": str(e)
            }
    
    def analyze_and_solve_question(self, user_id: str, question_text: str, 
                                 user_answer: Optional[str] = None) -> Dict[str, Any]:
        """
        åˆ†æå¹¶è§£ç­”è¯•é¢˜
        
        Args:
            user_id: ç”¨æˆ·ID
            question_text: é¢˜ç›®æ–‡æœ¬
            user_answer: ç”¨æˆ·ç­”æ¡ˆï¼ˆå¯é€‰ï¼‰
        
        Returns:
            åˆ†æç»“æœ
        """
        try:
            # è·å–ç”¨æˆ·å­¦ä¹ æƒ…å†µ
            user_profile = self._get_user_learning_profile(user_id)
            
            # æ„å»ºåˆ†ææç¤ºè¯
            analysis_prompt = self._build_question_analysis_prompt(
                question_text, user_answer, user_profile
            )
            
            # è°ƒç”¨å¤§æ¨¡å‹è¿›è¡Œåˆ†æ
            analysis_result = llm_service.generate_text(
                prompt=analysis_prompt,
                max_tokens=1000,
                temperature=0.3
            )
            
            # è§£æåˆ†æç»“æœ
            parsed_result = self._parse_analysis_result(analysis_result)
            
            # ç”Ÿæˆä¸ªæ€§åŒ–å»ºè®®
            personalized_suggestions = self._generate_personalized_suggestions(
                user_id, question_text, parsed_result
            )
            
            return {
                "success": True,
                "analysis": parsed_result,
                "suggestions": personalized_suggestions,
                "assistant_comment": self._generate_assistant_comment(parsed_result, user_answer),
                "timestamp": datetime.now().isoformat()
            }
            
        except Exception as e:
            logger.error(f"é¢˜ç›®åˆ†æå¤±è´¥: {str(e)}")
            return {
                "success": False,
                "message": "é¢˜ç›®åˆ†æå¤±è´¥ï¼Œè¯·é‡è¯•ã€‚",
                "error": str(e)
            }
    
    def get_personalized_recommendations(self, user_id: str) -> Dict[str, Any]:
        """
        è·å–ä¸ªæ€§åŒ–å­¦ä¹ å»ºè®®
        
        Args:
            user_id: ç”¨æˆ·ID
        
        Returns:
            ä¸ªæ€§åŒ–å»ºè®®
        """
        try:
            # è·å–ç”¨æˆ·å­¦ä¹ è¯Šæ–­æ•°æ®
            user_profile = self._get_user_learning_profile(user_id)
            diagnosis_data = self._get_user_diagnosis_data(user_id)
            
            # ç”Ÿæˆä¸ªæ€§åŒ–å»ºè®®
            recommendations = {
                "daily_study_plan": self._generate_daily_study_plan(user_profile, diagnosis_data),
                "weak_points_focus": self._get_weak_points_recommendations(user_id),
                "practice_suggestions": self._generate_practice_suggestions(user_profile),
                "motivational_message": self._generate_motivational_message(user_profile)
            }
            
            return {
                "success": True,
                "recommendations": recommendations,
                "timestamp": datetime.now().isoformat()
            }
            
        except Exception as e:
            logger.error(f"è·å–ä¸ªæ€§åŒ–å»ºè®®å¤±è´¥: {str(e)}")
            return {
                "success": False,
                "message": "è·å–å»ºè®®å¤±è´¥ï¼Œè¯·é‡è¯•ã€‚",
                "error": str(e)
            }
    
    def analyze_document_content(self, user_id: str, document_id: str, question: Optional[str] = None) -> Dict[str, Any]:
        """
        åˆ†æPDFæ–‡æ¡£å†…å®¹å¹¶å›ç­”ç›¸å…³é—®é¢˜
        
        Args:
            user_id: ç”¨æˆ·ID
            document_id: æ–‡æ¡£ID
            question: ç”¨æˆ·é—®é¢˜ï¼ˆå¯é€‰ï¼‰
        
        Returns:
            æ–‡æ¡£åˆ†æç»“æœ
        """
        try:
            document_service = get_document_service()
            
            # è·å–æ–‡æ¡£ä¿¡æ¯
            document_info = document_service.get_document_info(document_id)
            if not document_info:
                return {
                    "success": False,
                    "message": "æ–‡æ¡£ä¸å­˜åœ¨æˆ–å·²è¢«åˆ é™¤"
                }
            
            # è·å–æ–‡æ¡£å†…å®¹
            document_content = document_service.get_document_content(document_id)
            if not document_content:
                return {
                    "success": False,
                    "message": "æ— æ³•è·å–æ–‡æ¡£å†…å®¹"
                }
            
            # è·å–ç”¨æˆ·å­¦ä¹ æ¡£æ¡ˆ
            user_profile = self._get_user_learning_profile(user_id)
            
            # æ„å»ºåˆ†ææç¤ºè¯
            if question:
                # åŸºäºé—®é¢˜çš„æ–‡æ¡£é—®ç­”
                analysis_prompt = self._build_document_qa_prompt(
                    document_info, document_content, question, user_profile
                )
            else:
                # æ–‡æ¡£å†…å®¹æ€»ç»“åˆ†æ
                analysis_prompt = self._build_document_analysis_prompt(
                    document_info, document_content, user_profile
                )
            
            # è°ƒç”¨å¤§æ¨¡å‹è¿›è¡Œåˆ†æ
            analysis_result = llm_service.generate_text(
                prompt=analysis_prompt,
                max_tokens=1000,
                temperature=0.3
            )
            
            # ç”Ÿæˆå­¦ä¹ å»ºè®®
            learning_suggestions = self._generate_document_learning_suggestions(
                user_id, document_info, document_content
            )
            
            return {
                "success": True,
                "document_info": {
                    "title": document_info.get('title', ''),
                    "category": document_info.get('category', ''),
                    "upload_time": document_info.get('upload_time', '')
                },
                "analysis": analysis_result,
                "learning_suggestions": learning_suggestions,
                "timestamp": datetime.now().isoformat()
            }
            
        except Exception as e:
            logger.error(f"æ–‡æ¡£åˆ†æå¤±è´¥: {str(e)}")
            return {
                "success": False,
                "message": "æ–‡æ¡£åˆ†æå¤±è´¥ï¼Œè¯·é‡è¯•ã€‚",
                "error": str(e)
            }
    
    def search_documents_by_content(self, user_id: str, query: str) -> Dict[str, Any]:
        """
        æ ¹æ®å†…å®¹æœç´¢ç”¨æˆ·çš„PDFæ–‡æ¡£
        
        Args:
            user_id: ç”¨æˆ·ID
            query: æœç´¢æŸ¥è¯¢
        
        Returns:
            æœç´¢ç»“æœ
        """
        try:
            document_service = get_document_service()
            
            # æœç´¢æ–‡æ¡£
            search_results = document_service.search_documents(
                query=query,
                user_id=user_id,
                tenant_id="default"
            )
            
            if not search_results:
                return {
                    "success": True,
                    "results": [],
                    "message": "æ²¡æœ‰æ‰¾åˆ°ç›¸å…³æ–‡æ¡£ï¼Œå»ºè®®ä¸Šä¼ æ›´å¤šå­¦ä¹ èµ„æ–™ã€‚",
                    "suggestions": [
                        "å°è¯•ä½¿ç”¨ä¸åŒçš„å…³é”®è¯æœç´¢",
                        "ä¸Šä¼ æ›´å¤šç›¸å…³çš„PDFæ–‡æ¡£",
                        "æ£€æŸ¥æœç´¢è¯çš„æ‹¼å†™"
                    ]
                }
            
            # ä¸ºæ¯ä¸ªç»“æœç”Ÿæˆç®€è¦è¯´æ˜
            enhanced_results = []
            for doc in search_results[:5]:  # é™åˆ¶è¿”å›å‰5ä¸ªç»“æœ
                doc_summary = self._generate_document_summary(doc)
                enhanced_results.append({
                    "document_id": doc.get('id'),
                    "title": doc.get('title', ''),
                    "category": doc.get('category', ''),
                    "relevance_score": doc.get('relevance_score', 0),
                    "summary": doc_summary,
                    "upload_time": doc.get('upload_time', '')
                })
            
            return {
                "success": True,
                "results": enhanced_results,
                "total_found": len(search_results),
                "message": f"æ‰¾åˆ° {len(search_results)} ä¸ªç›¸å…³æ–‡æ¡£",
                "timestamp": datetime.now().isoformat()
            }
            
        except Exception as e:
            logger.error(f"æ–‡æ¡£æœç´¢å¤±è´¥: {str(e)}")
            return {
                "success": False,
                "message": "æ–‡æ¡£æœç´¢å¤±è´¥ï¼Œè¯·é‡è¯•ã€‚",
                "error": str(e)
            }
    
    def _get_user_learning_profile(self, user_id: str) -> Dict[str, Any]:
        """
        è·å–ç”¨æˆ·å­¦ä¹ æ¡£æ¡ˆ
        """
        try:
            user = User.query.get(user_id)
            if not user:
                return {}
            
            # è·å–æœ€è¿‘çš„è¯Šæ–­æŠ¥å‘Š
            recent_reports = DiagnosisReport.query.filter_by(
                user_id=user_id
            ).order_by(DiagnosisReport.created_at.desc()).limit(3).all()
            
            profile = {
                "user_id": user_id,
                "username": user.username,
                "real_name": getattr(user, 'real_name', None),
                "nickname": getattr(user, 'nickname', None),
                "preferred_greeting": getattr(user, 'preferred_greeting', 'casual'),
                "grade_level": getattr(user, 'grade_level', 'æœªçŸ¥'),
                "recent_reports": len(recent_reports),
                "learning_style": self._infer_learning_style(recent_reports),
                "strong_subjects": self._get_strong_subjects(recent_reports),
                "weak_areas": self._get_weak_areas(user_id)
            }
            
            return profile
            
        except Exception as e:
            logger.error(f"è·å–ç”¨æˆ·å­¦ä¹ æ¡£æ¡ˆå¤±è´¥: {str(e)}")
            return {}
    
    def _retrieve_relevant_documents(self, user_id: str, query: str) -> List[Dict[str, Any]]:
        """
        æ£€ç´¢ä¸æŸ¥è¯¢ç›¸å…³çš„æ–‡æ¡£
        
        Args:
            user_id: ç”¨æˆ·ID
            query: æŸ¥è¯¢æ–‡æœ¬
        
        Returns:
            ç›¸å…³æ–‡æ¡£åˆ—è¡¨
        """
        try:
            # ä½¿ç”¨å‘é‡æ•°æ®åº“è¿›è¡Œè¯­ä¹‰æœç´¢
            similar_docs = vector_db_service.search_similar_documents(
                query=query,
                top_k=3,
                similarity_threshold=0.4
            )
            
            if not similar_docs:
                return []
            
            # è·å–æ–‡æ¡£è¯¦ç»†ä¿¡æ¯
            document_service = get_document_service()
            relevant_documents = []
            
            for doc in similar_docs:
                try:
                    # æ ¹æ®æ–‡æ¡£ç±»å‹è·å–è¯¦ç»†ä¿¡æ¯
                    if doc['document_type'] == 'document':
                        doc_info = document_service.get_document_info(doc['document_id'])
                        if doc_info:
                            relevant_documents.append({
                                'id': doc['document_id'],
                                'type': 'document',
                                'title': doc_info.get('title', 'æœªçŸ¥æ–‡æ¡£'),
                                'content_snippet': doc['content'][:200] + '...' if len(doc['content']) > 200 else doc['content'],
                                'similarity': doc['similarity'],
                                'preview_url': f"/api/document/{doc['document_id']}/preview",
                                'metadata': doc.get('metadata', {})
                            })
                    elif doc['document_type'] == 'exam_paper':
                        # å¤„ç†è¯•å·æ–‡æ¡£
                        relevant_documents.append({
                            'id': doc['document_id'],
                            'type': 'exam_paper',
                            'title': f"è¯•å· {doc['document_id']}",
                            'content_snippet': doc['content'][:200] + '...' if len(doc['content']) > 200 else doc['content'],
                            'similarity': doc['similarity'],
                            'preview_url': f"/api/exam_papers/{doc['document_id']}/preview",
                            'metadata': doc.get('metadata', {})
                        })
                except Exception as e:
                    logger.warning(f"è·å–æ–‡æ¡£ {doc['document_id']} è¯¦ç»†ä¿¡æ¯å¤±è´¥: {str(e)}")
                    continue
            
            logger.info(f"ä¸ºæŸ¥è¯¢ '{query}' æ‰¾åˆ° {len(relevant_documents)} ä¸ªç›¸å…³æ–‡æ¡£")
            return relevant_documents
            
        except Exception as e:
            logger.error(f"æ–‡æ¡£æ£€ç´¢å¤±è´¥: {str(e)}")
            return []
    
    def _retrieve_comprehensive_data(self, user_id: str, query: str) -> Dict[str, Any]:
        """
        æ£€ç´¢ç»¼åˆæ•°æ®ï¼ŒåŒ…æ‹¬æ–‡æ¡£ã€è¯•å·ã€é”™é¢˜è®°å½•å’Œå­¦ä¹ æƒ…å†µ
        
        Args:
            user_id: ç”¨æˆ·ID
            query: æŸ¥è¯¢å†…å®¹
        
        Returns:
            ç»¼åˆæ•°æ®å­—å…¸
        """
        try:
            # æ£€ç´¢ç›¸å…³æ–‡æ¡£
            documents = self._retrieve_relevant_documents(user_id, query)
            
            # æ£€ç´¢è¯•å·æ•°æ®
            exam_papers = self._get_exam_papers_data(user_id, query)
            
            # æ£€ç´¢é”™é¢˜è®°å½•
            mistake_records = self._get_mistake_records_data(user_id, query)
            
            # æ£€ç´¢è€ƒè¯•ä¼šè¯
            exam_sessions = self._get_exam_sessions_data(user_id, query)
            
            # æ£€ç´¢å­¦ä¹ è®°å½•
            study_records = self._get_study_records_data(user_id, query)
            
            # è·å–å­¦ä¹ åˆ†ææ•°æ®
            learning_analytics = self._get_learning_analytics_data(user_id)
            
            return {
                'documents': documents,
                'exam_papers': exam_papers,
                'mistake_records': mistake_records,
                'exam_sessions': exam_sessions,
                'study_records': study_records,
                'learning_analytics': learning_analytics
            }
            
        except Exception as e:
            logger.error(f"æ£€ç´¢ç»¼åˆæ•°æ®å¤±è´¥: {str(e)}")
            return {}
    
    def _build_chat_prompt(self, user_profile: Dict, context: Optional[Dict] = None, 
                          relevant_documents: Optional[List[Dict]] = None) -> str:
        """
        æ„å»ºå¯¹è¯æç¤ºè¯
        """
        # ç¡®å®šç”¨æˆ·ç§°å‘¼
        user_nickname = user_profile.get('nickname') or user_profile.get('real_name') or user_profile.get('username', 'åŒå­¦')
        preferred_greeting = user_profile.get('preferred_greeting', 'casual')
        
        # æ ¹æ®é—®å€™åå¥½è®¾ç½®ç§°å‘¼æ–¹å¼
        greeting_styles = {
            'formal': f'æ‚¨å¥½ï¼Œ{user_nickname}',
            'casual': f'å—¨ï¼Œ{user_nickname}',
            'friendly': f'{user_nickname}ï¼Œä½ å¥½',
            'professional': f'{user_nickname}åŒå­¦'
        }
        
        greeting_style = greeting_styles.get(preferred_greeting, f'ä½ å¥½ï¼Œ{user_nickname}')
        
        base_prompt = f"""
ä½ æ˜¯{self.assistant_name}ï¼Œä¸€ä¸ªå‹å–„ã€è€å¿ƒã€ä¸“ä¸šçš„AIå­¦ä¹ åŠ©æ‰‹ã€‚ä½ çš„ä»»åŠ¡æ˜¯å¸®åŠ©å­¦ç”Ÿæé«˜å­¦ä¹ æ•ˆæœã€‚

ç”¨æˆ·ä¿¡æ¯ï¼š
- ç§°å‘¼ï¼š{user_nickname}
- é—®å€™æ–¹å¼ï¼š{greeting_style}
- å¹´çº§ï¼š{user_profile.get('grade_level', 'æœªçŸ¥')}
- æ“…é•¿ç§‘ç›®ï¼š{', '.join(user_profile.get('strong_subjects', []))}
- è–„å¼±ç¯èŠ‚ï¼š{', '.join(user_profile.get('weak_areas', []))}

å¯¹è¯é£æ ¼è¦æ±‚ï¼š
- åœ¨å›å¤å¼€å§‹æ—¶ä½¿ç”¨è®¾å®šçš„é—®å€™æ–¹å¼ç§°å‘¼ç”¨æˆ·
- åœ¨å¯¹è¯ä¸­é€‚å½“ä½¿ç”¨ç”¨æˆ·çš„ç§°å‘¼
- æ ¹æ®ç”¨æˆ·åå¥½è°ƒæ•´è¯­è¨€é£æ ¼ï¼ˆæ­£å¼/äº²åˆ‡/å‹å¥½/ä¸“ä¸šï¼‰
- ä½¿ç”¨å‹å–„ã€é¼“åŠ±æ€§çš„è¯­è¨€
- æ ¹æ®ç”¨æˆ·çš„å­¦ä¹ æƒ…å†µæä¾›é’ˆå¯¹æ€§å»ºè®®
- é€‚å½“ä½¿ç”¨è¡¨æƒ…ç¬¦å·å¢åŠ äº²å’ŒåŠ›
- ä¿æŒä¸“ä¸šæ€§ï¼Œæä¾›å‡†ç¡®çš„å­¦ä¹ æŒ‡å¯¼
"""
        
        # æ·»åŠ ç›¸å…³æ–‡æ¡£ä¿¡æ¯
        if relevant_documents:
            base_prompt += "\n\nç›¸å…³å‚è€ƒèµ„æ–™ï¼š"
            for i, doc in enumerate(relevant_documents, 1):
                doc_type_name = "æ–‡æ¡£" if doc['type'] == 'document' else "è¯•å·"
                base_prompt += f"""
{i}. {doc_type_name}ï¼š{doc['title']}
   å†…å®¹æ‘˜è¦ï¼š{doc['content_snippet']}
   é¢„è§ˆé“¾æ¥ï¼š{doc['preview_url']}
   ç›¸å…³åº¦ï¼š{doc['similarity']:.2f}"""
            
            base_prompt += "\n\nå›ç­”æŒ‡å¯¼ï¼š"
            base_prompt += "\n- å½“å›ç­”æ¶‰åŠä¸Šè¿°å‚è€ƒèµ„æ–™æ—¶ï¼Œè¯·å¼•ç”¨ç›¸å…³å†…å®¹å¹¶æä¾›é¢„è§ˆé“¾æ¥"
            base_prompt += "\n- ä½¿ç”¨æ ¼å¼ï¼š[æ–‡æ¡£æ ‡é¢˜](é¢„è§ˆé“¾æ¥) æ¥å¼•ç”¨æ–‡æ¡£"
            base_prompt += "\n- ç»“åˆå‚è€ƒèµ„æ–™ä¸ºç”¨æˆ·æä¾›æ›´å‡†ç¡®ã€è¯¦ç»†çš„è§£ç­”"
        
        if context:
            base_prompt += f"\n\nå¯¹è¯ä¸Šä¸‹æ–‡ï¼š{json.dumps(context, ensure_ascii=False)}"
        
        return base_prompt
    
    def _build_comprehensive_chat_prompt(self, user_profile: Dict, context: Optional[Dict] = None, 
                                       comprehensive_data: Optional[Dict] = None) -> str:
        """
        æ„å»ºåŒ…å«ç»¼åˆæ•°æ®çš„å¯¹è¯æç¤ºè¯
        """
        # ç¡®å®šç”¨æˆ·ç§°å‘¼
        user_nickname = user_profile.get('nickname') or user_profile.get('real_name') or user_profile.get('username', 'åŒå­¦')
        preferred_greeting = user_profile.get('preferred_greeting', 'casual')
        
        # æ ¹æ®é—®å€™åå¥½è®¾ç½®ç§°å‘¼æ–¹å¼
        greeting_styles = {
            'formal': f'æ‚¨å¥½ï¼Œ{user_nickname}',
            'casual': f'å—¨ï¼Œ{user_nickname}',
            'friendly': f'{user_nickname}ï¼Œä½ å¥½',
            'professional': f'{user_nickname}åŒå­¦'
        }
        
        greeting_style = greeting_styles.get(preferred_greeting, f'ä½ å¥½ï¼Œ{user_nickname}')
        
        base_prompt = f"""
ä½ æ˜¯{self.assistant_name}ï¼Œä¸€ä¸ªå‹å–„ã€è€å¿ƒã€ä¸“ä¸šçš„AIå­¦ä¹ åŠ©æ‰‹ã€‚ä½ çš„ä»»åŠ¡æ˜¯å¸®åŠ©å­¦ç”Ÿæé«˜å­¦ä¹ æ•ˆæœã€‚

ç”¨æˆ·ä¿¡æ¯ï¼š
- ç§°å‘¼ï¼š{user_nickname}
- é—®å€™æ–¹å¼ï¼š{greeting_style}
- å¹´çº§ï¼š{user_profile.get('grade_level', 'æœªçŸ¥')}
- æ“…é•¿ç§‘ç›®ï¼š{', '.join(user_profile.get('strong_subjects', []))}
- è–„å¼±ç¯èŠ‚ï¼š{', '.join(user_profile.get('weak_areas', []))}

å¯¹è¯é£æ ¼è¦æ±‚ï¼š
- åœ¨å›å¤å¼€å§‹æ—¶ä½¿ç”¨è®¾å®šçš„é—®å€™æ–¹å¼ç§°å‘¼ç”¨æˆ·
- åœ¨å¯¹è¯ä¸­é€‚å½“ä½¿ç”¨ç”¨æˆ·çš„ç§°å‘¼
- æ ¹æ®ç”¨æˆ·åå¥½è°ƒæ•´è¯­è¨€é£æ ¼ï¼ˆæ­£å¼/äº²åˆ‡/å‹å¥½/ä¸“ä¸šï¼‰
- ä½¿ç”¨å‹å–„ã€é¼“åŠ±æ€§çš„è¯­è¨€
- æ ¹æ®ç”¨æˆ·çš„å­¦ä¹ æƒ…å†µæä¾›é’ˆå¯¹æ€§å»ºè®®
- é€‚å½“ä½¿ç”¨è¡¨æƒ…ç¬¦å·å¢åŠ äº²å’ŒåŠ›
- ä¿æŒä¸“ä¸šæ€§ï¼Œæä¾›å‡†ç¡®çš„å­¦ä¹ æŒ‡å¯¼
"""
        
        if comprehensive_data:
            # æ·»åŠ æ–‡æ¡£ä¿¡æ¯
            documents = comprehensive_data.get('documents', [])
            if documents:
                base_prompt += "\n\nç›¸å…³æ–‡æ¡£èµ„æ–™ï¼š"
                for i, doc in enumerate(documents[:3], 1):
                    base_prompt += f"\n{i}. {doc['title']} - {doc['content_snippet'][:100]}..."
            
            # æ·»åŠ è¯•å·ä¿¡æ¯
            exam_papers = comprehensive_data.get('exam_papers', [])
            if exam_papers:
                base_prompt += "\n\nç›¸å…³è¯•å·ï¼š"
                for i, paper in enumerate(exam_papers[:3], 1):
                    base_prompt += f"\n{i}. {paper['title']} ({paper['year']}å¹´ {paper['exam_type']})"
            
            # æ·»åŠ é”™é¢˜è®°å½•ä¿¡æ¯
            mistake_records = comprehensive_data.get('mistake_records', [])
            if mistake_records:
                base_prompt += f"\n\nç”¨æˆ·é”™é¢˜æƒ…å†µï¼šå…±æœ‰{len(mistake_records)}é“é”™é¢˜è®°å½•"
                resolved_count = sum(1 for m in mistake_records if m.get('is_resolved'))
                base_prompt += f"ï¼Œå·²è§£å†³{resolved_count}é“"
            
            # æ·»åŠ å­¦ä¹ åˆ†ææ•°æ®
            learning_analytics = comprehensive_data.get('learning_analytics', {})
            if learning_analytics:
                mistake_analysis = learning_analytics.get('mistake_analysis', {})
                exam_performance = learning_analytics.get('exam_performance', {})
                if mistake_analysis.get('total_mistakes', 0) > 0:
                    base_prompt += f"\n\nå­¦ä¹ åˆ†æï¼šæœ€è¿‘30å¤©é”™é¢˜{mistake_analysis['total_mistakes']}é“ï¼Œè§£å†³ç‡{mistake_analysis.get('resolution_rate', 0):.1f}%"
                if exam_performance.get('total_exams', 0) > 0:
                    base_prompt += f"ï¼Œå¹³å‡è€ƒè¯•æˆç»©{exam_performance.get('average_score', 0):.1f}åˆ†"
            
            base_prompt += "\n\nå›ç­”æŒ‡å¯¼ï¼š"
            base_prompt += "\n- ç»“åˆç”¨æˆ·çš„å­¦ä¹ æ•°æ®æä¾›ä¸ªæ€§åŒ–å»ºè®®"
            base_prompt += "\n- é’ˆå¯¹é”™é¢˜è®°å½•å’Œè–„å¼±ç¯èŠ‚ç»™å‡ºå…·ä½“æ”¹è¿›æ–¹æ¡ˆ"
            base_prompt += "\n- æ¨èç›¸å…³çš„å­¦ä¹ èµ„æ–™å’Œç»ƒä¹ é¢˜ç›®"
            base_prompt += "\n- é¼“åŠ±ç”¨æˆ·å¹¶æä¾›å­¦ä¹ åŠ¨åŠ›"
        
        if context:
            base_prompt += f"\n\nå¯¹è¯ä¸Šä¸‹æ–‡ï¼š{json.dumps(context, ensure_ascii=False)}"
        
        return base_prompt
    
    def _analyze_extracted_text(self, text: str, user_id: str) -> Dict[str, Any]:
        """
        åˆ†æOCRæå–çš„æ–‡æœ¬
        """
        prompt = f"""
è¯·åˆ†æä»¥ä¸‹ä»å›¾ç‰‡ä¸­æå–çš„æ–‡æœ¬ï¼Œåˆ¤æ–­æ˜¯å¦ä¸ºè¯•é¢˜ï¼Œå¹¶æå–å…³é”®ä¿¡æ¯ï¼š

æå–çš„æ–‡æœ¬ï¼š
{text}

è¯·ä»¥JSONæ ¼å¼è¿”å›åˆ†æç»“æœï¼ŒåŒ…å«ï¼š
1. is_question: æ˜¯å¦ä¸ºè¯•é¢˜ï¼ˆtrue/falseï¼‰
2. subject: ç§‘ç›®ï¼ˆå¦‚ï¼šæ•°å­¦ã€ç‰©ç†ã€åŒ–å­¦ç­‰ï¼‰
3. question_type: é¢˜å‹ï¼ˆå¦‚ï¼šé€‰æ‹©é¢˜ã€å¡«ç©ºé¢˜ã€è§£ç­”é¢˜ç­‰ï¼‰
4. difficulty_level: éš¾åº¦ç­‰çº§ï¼ˆ1-5ï¼‰
5. key_concepts: æ¶‰åŠçš„å…³é”®æ¦‚å¿µ
6. cleaned_question: æ¸…ç†åçš„é¢˜ç›®æ–‡æœ¬
"""
        
        try:
            result = llm_service.generate_text(prompt, max_tokens=500)
            return json.loads(result)
        except:
            return {
                "is_question": True,
                "subject": "æœªçŸ¥",
                "question_type": "æœªçŸ¥",
                "difficulty_level": 3,
                "key_concepts": [],
                "cleaned_question": text
            }
    
    def _describe_image_content(self, image_data: str, user_id: str, extracted_text: Optional[str] = None) -> str:
        """
        æè¿°å›¾ç‰‡å†…å®¹
        
        Args:
            image_data: Base64ç¼–ç çš„å›¾ç‰‡æ•°æ®
            user_id: ç”¨æˆ·ID
            extracted_text: OCRæå–çš„æ–‡æœ¬ï¼ˆå¯é€‰ï¼‰
        
        Returns:
            å›¾ç‰‡å†…å®¹æè¿°
        """
        try:
            # æ„å»ºæè¿°æç¤º
            if extracted_text:
                prompt = f"""
è¯·æ ¹æ®ä»¥ä¸‹ä¿¡æ¯æè¿°è¿™å¼ å›¾ç‰‡çš„å†…å®¹ï¼š

å›¾ç‰‡ä¸­çš„æ–‡å­—å†…å®¹ï¼š
{extracted_text}

è¯·ç”¨å‹å¥½ã€è¯¦ç»†çš„è¯­è¨€æè¿°è¿™å¼ å›¾ç‰‡ï¼ŒåŒ…æ‹¬ï¼š
1. å›¾ç‰‡çš„ä¸»è¦å†…å®¹å’Œä¸»é¢˜
2. å›¾ç‰‡ä¸­çš„æ–‡å­—ä¿¡æ¯
3. å¯èƒ½çš„ç”¨é€”æˆ–èƒŒæ™¯
4. å…¶ä»–å€¼å¾—æ³¨æ„çš„ç»†èŠ‚

è¯·ä»¥è‡ªç„¶ã€æ˜“æ‡‚çš„æ–¹å¼æè¿°ï¼Œå°±åƒåœ¨å’Œæœ‹å‹èŠå¤©ä¸€æ ·ã€‚
"""
            else:
                prompt = """
è¿™æ˜¯ä¸€å¼ æ²¡æœ‰æ–‡å­—å†…å®¹çš„å›¾ç‰‡ã€‚è¯·æè¿°è¿™å¼ å›¾ç‰‡å¯èƒ½åŒ…å«çš„å†…å®¹ï¼Œæ¯”å¦‚ï¼š
1. å¯èƒ½æ˜¯ä»€ä¹ˆç±»å‹çš„å›¾ç‰‡ï¼ˆç…§ç‰‡ã€å›¾è¡¨ã€æ’ç”»ç­‰ï¼‰
2. å¯èƒ½çš„ä¸»é¢˜æˆ–å†…å®¹
3. å»ºè®®ç”¨æˆ·å¦‚ä½•æ›´å¥½åœ°ä½¿ç”¨å›¾ç‰‡è¯†åˆ«åŠŸèƒ½

è¯·ç”¨å‹å¥½ã€é¼“åŠ±çš„è¯­æ°”å›å¤ã€‚
"""
            
            result = llm_service.generate_text(prompt, max_tokens=300)
            return result.strip()
            
        except Exception as e:
            logger.error(f"å›¾ç‰‡å†…å®¹æè¿°å¤±è´¥: {str(e)}")
            if extracted_text:
                return f"æˆ‘çœ‹åˆ°è¿™å¼ å›¾ç‰‡åŒ…å«ä»¥ä¸‹æ–‡å­—å†…å®¹ï¼š{extracted_text[:200]}...\n\nè¿™çœ‹èµ·æ¥ä¸æ˜¯ä¸€é“é¢˜ç›®ï¼Œè€Œæ˜¯åŒ…å«æ–‡å­—ä¿¡æ¯çš„å›¾ç‰‡ã€‚å¦‚æœä½ éœ€è¦æˆ‘å¸®åŠ©åˆ†æç‰¹å®šå†…å®¹ï¼Œè¯·å‘Šè¯‰æˆ‘ä½ æƒ³äº†è§£ä»€ä¹ˆï¼"
            else:
                return "è¿™å¼ å›¾ç‰‡æ²¡æœ‰åŒ…å«æ–‡å­—å†…å®¹ã€‚å¦‚æœä½ æƒ³è®©æˆ‘è¯†åˆ«é¢˜ç›®ï¼Œè¯·ç¡®ä¿å›¾ç‰‡æ¸…æ™°ä¸”åŒ…å«é¢˜ç›®æ–‡å­—ã€‚æˆ‘ä¹Ÿå¯ä»¥å¸®ä½ åˆ†æå…¶ä»–åŒ…å«æ–‡å­—çš„å­¦ä¹ ææ–™ï¼"
    
    def _build_question_analysis_prompt(self, question: str, user_answer: Optional[str], 
                                      user_profile: Dict) -> str:
        """
        æ„å»ºé¢˜ç›®åˆ†ææç¤ºè¯
        """
        # ç¡®å®šç”¨æˆ·ç§°å‘¼
        user_nickname = user_profile.get('nickname') or user_profile.get('real_name') or user_profile.get('username', 'åŒå­¦')
        preferred_greeting = user_profile.get('preferred_greeting', 'casual')
        
        # æ ¹æ®é—®å€™åå¥½è®¾ç½®ç§°å‘¼æ–¹å¼
        greeting_styles = {
            'formal': f'æ‚¨å¥½ï¼Œ{user_nickname}',
            'casual': f'å—¨ï¼Œ{user_nickname}',
            'friendly': f'{user_nickname}ï¼Œä½ å¥½',
            'professional': f'{user_nickname}åŒå­¦'
        }
        
        greeting_style = greeting_styles.get(preferred_greeting, f'ä½ å¥½ï¼Œ{user_nickname}')
        
        prompt = f"""
ä½œä¸ºä¸“ä¸šçš„å­¦ä¹ åŠ©æ‰‹{self.assistant_name}ï¼Œè¯·åˆ†æä»¥ä¸‹é¢˜ç›®ï¼š

é¢˜ç›®ï¼š
{question}
"""
        
        if user_answer:
            prompt += f"\n\nå­¦ç”Ÿç­”æ¡ˆï¼š\n{user_answer}"
        
        prompt += f"""

ç”¨æˆ·ä¿¡æ¯ï¼š
- ç§°å‘¼ï¼š{user_nickname}
- é—®å€™æ–¹å¼ï¼š{greeting_style}
- æ“…é•¿é¢†åŸŸï¼š{', '.join(user_profile.get('strong_subjects', []))}
- è–„å¼±ç¯èŠ‚ï¼š{', '.join(user_profile.get('weak_areas', []))}

è¯·æä¾›ï¼š
1. é¢˜ç›®è§£æå’Œæ ‡å‡†ç­”æ¡ˆ
2. è§£é¢˜æ€è·¯å’Œæ–¹æ³•
3. ç›¸å…³çŸ¥è¯†ç‚¹
4. å¸¸è§é”™è¯¯åˆ†æ
5. é’ˆå¯¹è¯¥ç”¨æˆ·çš„ä¸ªæ€§åŒ–å»ºè®®

å›ç­”è¦æ±‚ï¼š
- åœ¨å›å¤å¼€å§‹æ—¶ä½¿ç”¨è®¾å®šçš„é—®å€™æ–¹å¼ç§°å‘¼ç”¨æˆ·
- åœ¨åˆ†æè¿‡ç¨‹ä¸­é€‚å½“ä½¿ç”¨ç”¨æˆ·çš„ç§°å‘¼
- æ ¹æ®ç”¨æˆ·åå¥½è°ƒæ•´è¯­è¨€é£æ ¼ï¼ˆæ­£å¼/äº²åˆ‡/å‹å¥½/ä¸“ä¸šï¼‰
- ç”¨å‹å–„ã€é¼“åŠ±çš„è¯­è°ƒå›ç­”
"""
        
        return prompt
    
    def _parse_analysis_result(self, result: str) -> Dict[str, Any]:
        """
        è§£æåˆ†æç»“æœ
        """
        # ç®€å•çš„ç»“æœè§£æï¼Œå®é™…å¯ä»¥æ›´å¤æ‚
        return {
            "solution": result,
            "confidence": 0.85,
            "key_points": [],
            "difficulty": "ä¸­ç­‰"
        }
    
    def _generate_personalized_suggestions(self, user_id: str, question: str, 
                                         analysis: Dict) -> List[str]:
        """
        ç”Ÿæˆä¸ªæ€§åŒ–å»ºè®®
        """
        suggestions = [
            "å»ºè®®å¤šç»ƒä¹ ç±»ä¼¼é¢˜å‹ï¼ŒåŠ å¼ºç†è§£",
            "å¯ä»¥å¤ä¹ ç›¸å…³çš„åŸºç¡€çŸ¥è¯†ç‚¹",
            "å°è¯•ç”¨ä¸åŒæ–¹æ³•è§£å†³åŒä¸€é—®é¢˜"
        ]
        
        # æ ¹æ®ç”¨æˆ·è–„å¼±ç¯èŠ‚æ·»åŠ é’ˆå¯¹æ€§å»ºè®®
        weak_areas = self._get_weak_areas(user_id)
        for area in weak_areas:
            suggestions.append(f"é’ˆå¯¹{area}ï¼Œå»ºè®®åŠ å¼ºä¸“é¡¹ç»ƒä¹ ")
        
        return suggestions[:5]  # é™åˆ¶å»ºè®®æ•°é‡
    
    def _generate_assistant_comment(self, analysis: Dict, user_answer: Optional[str]) -> str:
        """
        ç”ŸæˆåŠ©ç†è¯„è®º
        """
        if user_answer:
            return f"æˆ‘çœ‹äº†ä½ çš„ç­”æ¡ˆï¼Œ{self._get_encouraging_comment()}ï¼è®©æˆ‘æ¥å¸®ä½ åˆ†æä¸€ä¸‹è¿™é“é¢˜ã€‚"
        else:
            return f"è¿™æ˜¯ä¸€é“å¾ˆæœ‰æ„æ€çš„é¢˜ç›®ï¼{self._get_encouraging_comment()}ï¼Œæˆ‘æ¥ä¸ºä½ è¯¦ç»†è§£æã€‚"
    
    def _get_encouraging_comment(self) -> str:
        """
        è·å–é¼“åŠ±æ€§è¯„è®º
        """
        comments = [
            "ä½ å¾ˆç”¨å¿ƒåœ¨æ€è€ƒ",
            "ç»§ç»­ä¿æŒè¿™ç§å­¦ä¹ æ€åº¦",
            "ä½ çš„æ€è·¯å¾ˆä¸é”™",
            "å­¦ä¹ å°±æ˜¯è¦è¿™æ ·ç§¯æä¸»åŠ¨",
            "æˆ‘ç›¸ä¿¡ä½ èƒ½æŒæ¡è¿™ä¸ªçŸ¥è¯†ç‚¹"
        ]
        import random
        return random.choice(comments)
    
    def _get_weak_areas(self, user_id: str) -> List[str]:
        """
        è·å–ç”¨æˆ·è–„å¼±é¢†åŸŸ
        """
        try:
            weak_points = WeaknessPoint.query.filter_by(
                user_id=user_id
            ).order_by(WeaknessPoint.severity.desc()).limit(5).all()
            
            return [point.knowledge_point.name for point in weak_points 
                   if point.knowledge_point]
        except:
            return []
    
    def _generate_contextual_suggestions(self, user_id: str, message: str) -> List[str]:
        """
        ç”Ÿæˆä¸Šä¸‹æ–‡ç›¸å…³å»ºè®®
        """
        suggestions = []
        
        # æ ¹æ®æ¶ˆæ¯å†…å®¹ç”Ÿæˆå»ºè®®
        if "é¢˜ç›®" in message or "é¢˜" in message:
            suggestions.append("ğŸ“¸ å¯ä»¥æ‹ç…§ä¸Šä¼ é¢˜ç›®ï¼Œæˆ‘æ¥å¸®ä½ åˆ†æ")
        
        if "ä¸ä¼š" in message or "éš¾" in message:
            suggestions.append("ğŸ’ª åˆ«æ‹…å¿ƒï¼Œæˆ‘ä»¬ä¸€æ­¥æ­¥æ¥è§£å†³")
            suggestions.append("ğŸ“š æˆ‘å¯ä»¥æ¨èä¸€äº›ç›¸å…³çš„ç»ƒä¹ ")
        
        if "è€ƒè¯•" in message:
            suggestions.append("ğŸ“‹ æˆ‘å¯ä»¥å¸®ä½ åˆ¶å®šå¤ä¹ è®¡åˆ’")
            suggestions.append("ğŸ¯ è®©æˆ‘åˆ†æä¸€ä¸‹ä½ çš„è–„å¼±ç¯èŠ‚")
        
        return suggestions
    
    def _get_user_diagnosis_data(self, user_id: str) -> Dict[str, Any]:
        """
        è·å–ç”¨æˆ·è¯Šæ–­æ•°æ®
        """
        try:
            return DiagnosisService.get_diagnosis_statistics(user_id)
        except:
            return {}
    
    def _generate_daily_study_plan(self, user_profile: Dict, diagnosis_data: Dict) -> Dict[str, Any]:
        """
        ç”Ÿæˆæ¯æ—¥å­¦ä¹ è®¡åˆ’
        """
        return {
            "morning": "å¤ä¹ æ˜¨æ—¥é”™é¢˜ï¼Œå·©å›ºè–„å¼±çŸ¥è¯†ç‚¹",
            "afternoon": "æ–°çŸ¥è¯†å­¦ä¹ å’Œç†è§£",
            "evening": "ç»ƒä¹ é¢˜ç›®ï¼Œæ£€éªŒå­¦ä¹ æ•ˆæœ",
            "duration": "å»ºè®®æ¯ä¸ªæ—¶æ®µ30-45åˆ†é’Ÿ"
        }
    
    def _get_weak_points_recommendations(self, user_id: str) -> List[Dict[str, Any]]:
        """
        è·å–è–„å¼±ç‚¹å»ºè®®
        """
        weak_areas = self._get_weak_areas(user_id)
        recommendations = []
        
        for area in weak_areas[:3]:  # åªå–å‰3ä¸ª
            recommendations.append({
                "knowledge_point": area,
                "suggestion": f"å»ºè®®åŠ å¼º{area}çš„åŸºç¡€ç»ƒä¹ ",
                "priority": "é«˜"
            })
        
        return recommendations
    
    def _generate_practice_suggestions(self, user_profile: Dict) -> List[str]:
        """
        ç”Ÿæˆç»ƒä¹ å»ºè®®
        """
        return [
            "æ¯å¤©åšæŒåš3-5é“ç›¸å…³é¢˜ç›®",
            "å®šæœŸå›é¡¾é”™é¢˜æœ¬",
            "å°è¯•ä¸åŒéš¾åº¦çš„é¢˜ç›®æŒ‘æˆ˜è‡ªå·±",
            "ä¸åŒå­¦è®¨è®ºäº¤æµå­¦ä¹ å¿ƒå¾—"
        ]
    
    def _generate_motivational_message(self, user_profile: Dict) -> str:
        """
        ç”Ÿæˆæ¿€åŠ±æ¶ˆæ¯
        """
        messages = [
            "å­¦ä¹ æ˜¯ä¸€ä¸ªæŒç»­çš„è¿‡ç¨‹ï¼Œä½ å·²ç»åœ¨è¿›æ­¥çš„è·¯ä¸Šäº†ï¼ğŸ’ª",
            "æ¯ä¸€æ¬¡ç»ƒä¹ éƒ½æ˜¯å‘ç›®æ ‡è¿ˆè¿›çš„ä¸€æ­¥ï¼ŒåŠ æ²¹ï¼ğŸŒŸ",
            "ç›¸ä¿¡è‡ªå·±ï¼Œä½ æœ‰èƒ½åŠ›å…‹æœå­¦ä¹ ä¸­çš„å›°éš¾ï¼ğŸš€",
            "ä»Šå¤©çš„åŠªåŠ›å°±æ˜¯æ˜å¤©çš„æ”¶è·ï¼Œç»§ç»­ä¿æŒï¼ğŸ“ˆ"
        ]
        import random
        return random.choice(messages)
    
    def _infer_learning_style(self, reports: List) -> str:
        """
        æ¨æ–­å­¦ä¹ é£æ ¼
        """
        if not reports:
            return "æ¢ç´¢å‹"
        
        # ç®€å•çš„å­¦ä¹ é£æ ¼æ¨æ–­é€»è¾‘
        styles = ["è§†è§‰å‹", "å¬è§‰å‹", "åŠ¨æ‰‹å‹", "é€»è¾‘å‹"]
        import random
        return random.choice(styles)
    
    def _get_strong_subjects(self, reports: List) -> List[str]:
        """
        è·å–æ“…é•¿ç§‘ç›®
        """
        # ç®€å•å®ç°ï¼Œå®é™…åº”è¯¥åŸºäºè¯Šæ–­æ•°æ®åˆ†æ
        return ["æ•°å­¦", "ç‰©ç†"] if reports else []
    
    def _build_document_qa_prompt(self, document_info: Dict, document_content: str, 
                                question: str, user_profile: Dict) -> str:
        """
        æ„å»ºæ–‡æ¡£é—®ç­”æç¤ºè¯
        """
        # ç¡®å®šç”¨æˆ·ç§°å‘¼
        user_nickname = user_profile.get('nickname') or user_profile.get('real_name') or user_profile.get('username', 'åŒå­¦')
        preferred_greeting = user_profile.get('preferred_greeting', 'casual')
        
        # æ ¹æ®é—®å€™åå¥½è®¾ç½®ç§°å‘¼æ–¹å¼
        greeting_styles = {
            'formal': f'æ‚¨å¥½ï¼Œ{user_nickname}',
            'casual': f'å—¨ï¼Œ{user_nickname}',
            'friendly': f'{user_nickname}ï¼Œä½ å¥½',
            'professional': f'{user_nickname}åŒå­¦'
        }
        
        greeting_style = greeting_styles.get(preferred_greeting, f'ä½ å¥½ï¼Œ{user_nickname}')
        
        return f"""
ä½ æ˜¯é«˜å°åˆ†ï¼Œä¸€ä¸ªä¸“ä¸šçš„å­¦ä¹ åŠ©æ‰‹ã€‚ç”¨æˆ·ä¸Šä¼ äº†ä¸€ä¸ªPDFæ–‡æ¡£ï¼Œç°åœ¨æƒ³è¦è¯¢é—®ç›¸å…³é—®é¢˜ã€‚

æ–‡æ¡£ä¿¡æ¯ï¼š
- æ ‡é¢˜ï¼š{document_info.get('title', 'æœªçŸ¥')}
- åˆ†ç±»ï¼š{document_info.get('category', 'æœªçŸ¥')}

æ–‡æ¡£å†…å®¹ï¼ˆå‰2000å­—ç¬¦ï¼‰ï¼š
{document_content[:2000]}...

ç”¨æˆ·é—®é¢˜ï¼š{question}

ç”¨æˆ·ä¿¡æ¯ï¼š
- ç§°å‘¼ï¼š{user_nickname}
- é—®å€™æ–¹å¼ï¼š{greeting_style}
- å¹´çº§ï¼š{user_profile.get('grade_level', 'æœªçŸ¥')}
- å¼ºåŠ¿å­¦ç§‘ï¼š{', '.join(user_profile.get('strong_subjects', []))}
- è–„å¼±ç¯èŠ‚ï¼š{', '.join(user_profile.get('weak_areas', []))}

è¯·åŸºäºæ–‡æ¡£å†…å®¹å›ç­”ç”¨æˆ·çš„é—®é¢˜ï¼Œå¹¶ç»“åˆç”¨æˆ·çš„å­¦ä¹ æƒ…å†µç»™å‡ºä¸ªæ€§åŒ–çš„å­¦ä¹ å»ºè®®ã€‚
å›ç­”è¦æ±‚ï¼š
1. åœ¨å›å¤å¼€å§‹æ—¶ä½¿ç”¨è®¾å®šçš„é—®å€™æ–¹å¼ç§°å‘¼ç”¨æˆ·
2. ç›´æ¥å›ç­”ç”¨æˆ·é—®é¢˜
3. å¼•ç”¨æ–‡æ¡£ä¸­çš„ç›¸å…³å†…å®¹
4. æä¾›å­¦ä¹ å»ºè®®
5. æ ¹æ®ç”¨æˆ·åå¥½è°ƒæ•´è¯­è¨€é£æ ¼ï¼ˆæ­£å¼/äº²åˆ‡/å‹å¥½/ä¸“ä¸šï¼‰
6. è¯­è¨€è¦å‹å–„ã€é¼“åŠ±æ€§
"""
    
    def _build_document_analysis_prompt(self, document_info: Dict, document_content: str, 
                                      user_profile: Dict) -> str:
        """
        æ„å»ºæ–‡æ¡£åˆ†ææç¤ºè¯
        """
        # ç¡®å®šç”¨æˆ·ç§°å‘¼
        user_nickname = user_profile.get('nickname') or user_profile.get('real_name') or user_profile.get('username', 'åŒå­¦')
        preferred_greeting = user_profile.get('preferred_greeting', 'casual')
        
        # æ ¹æ®é—®å€™åå¥½è®¾ç½®ç§°å‘¼æ–¹å¼
        greeting_styles = {
            'formal': f'æ‚¨å¥½ï¼Œ{user_nickname}',
            'casual': f'å—¨ï¼Œ{user_nickname}',
            'friendly': f'{user_nickname}ï¼Œä½ å¥½',
            'professional': f'{user_nickname}åŒå­¦'
        }
        
        greeting_style = greeting_styles.get(preferred_greeting, f'ä½ å¥½ï¼Œ{user_nickname}')
        
        return f"""
ä½ æ˜¯é«˜å°åˆ†ï¼Œä¸€ä¸ªä¸“ä¸šçš„å­¦ä¹ åŠ©æ‰‹ã€‚ç”¨æˆ·ä¸Šä¼ äº†ä¸€ä¸ªPDFæ–‡æ¡£ï¼Œè¯·å¸®åŠ©åˆ†ææ–‡æ¡£å†…å®¹ã€‚

æ–‡æ¡£ä¿¡æ¯ï¼š
- æ ‡é¢˜ï¼š{document_info.get('title', 'æœªçŸ¥')}
- åˆ†ç±»ï¼š{document_info.get('category', 'æœªçŸ¥')}

æ–‡æ¡£å†…å®¹ï¼ˆå‰2000å­—ç¬¦ï¼‰ï¼š
{document_content[:2000]}...

ç”¨æˆ·ä¿¡æ¯ï¼š
- ç§°å‘¼ï¼š{user_nickname}
- é—®å€™æ–¹å¼ï¼š{greeting_style}
- å¹´çº§ï¼š{user_profile.get('grade_level', 'æœªçŸ¥')}
- å¼ºåŠ¿å­¦ç§‘ï¼š{', '.join(user_profile.get('strong_subjects', []))}
- è–„å¼±ç¯èŠ‚ï¼š{', '.join(user_profile.get('weak_areas', []))}

è¯·åˆ†æè¿™ä¸ªæ–‡æ¡£çš„å†…å®¹ï¼ŒåŒ…æ‹¬ï¼š
1. æ–‡æ¡£ä¸»è¦å†…å®¹æ¦‚è¿°
2. æ¶‰åŠçš„çŸ¥è¯†ç‚¹
3. éš¾åº¦ç­‰çº§è¯„ä¼°
4. å¯¹ç”¨æˆ·çš„å­¦ä¹ ä»·å€¼
5. ä¸ªæ€§åŒ–å­¦ä¹ å»ºè®®

å›ç­”è¦æ±‚ï¼š
- åœ¨å›å¤å¼€å§‹æ—¶ä½¿ç”¨è®¾å®šçš„é—®å€™æ–¹å¼ç§°å‘¼ç”¨æˆ·
- æ ¹æ®ç”¨æˆ·åå¥½è°ƒæ•´è¯­è¨€é£æ ¼ï¼ˆæ­£å¼/äº²åˆ‡/å‹å¥½/ä¸“ä¸šï¼‰
- å›ç­”è¦å‹å–„ã€ä¸“ä¸šï¼Œå¹¶å…·æœ‰é¼“åŠ±æ€§
"""
    
    def _generate_document_learning_suggestions(self, user_id: str, document_info: Dict, 
                                             document_content: str) -> List[str]:
        """
        ç”ŸæˆåŸºäºæ–‡æ¡£çš„å­¦ä¹ å»ºè®®
        """
        suggestions = []
        
        # åŸºäºæ–‡æ¡£ç±»åˆ«çš„å»ºè®®
        category = document_info.get('category', '')
        if 'æ•°å­¦' in category:
            suggestions.extend([
                "å»ºè®®å…ˆç†è§£åŸºæœ¬æ¦‚å¿µï¼Œå†ç»ƒä¹ ç›¸å…³é¢˜ç›®",
                "å¯ä»¥åˆ¶ä½œæ€ç»´å¯¼å›¾æ•´ç†çŸ¥è¯†ç‚¹"
            ])
        elif 'è¯­æ–‡' in category:
            suggestions.extend([
                "å»ºè®®å¤šè¯»å‡ éï¼Œç†è§£æ–‡ç« ç»“æ„å’Œä¸»æ—¨",
                "å¯ä»¥æ‘˜æŠ„å¥½è¯å¥½å¥ï¼Œç§¯ç´¯å†™ä½œç´ æ"
            ])
        elif 'è‹±è¯­' in category:
            suggestions.extend([
                "å»ºè®®å…ˆæŒæ¡ç”Ÿè¯ï¼Œå†ç†è§£æ–‡ç« å†…å®¹",
                "å¯ä»¥æœ—è¯»æ–‡ç« ï¼Œæé«˜è¯­æ„Ÿ"
            ])
        
        # é€šç”¨å»ºè®®
        suggestions.extend([
            "å»ºè®®åˆ¶å®šå­¦ä¹ è®¡åˆ’ï¼Œåˆ†é˜¶æ®µæŒæ¡å†…å®¹",
            "é‡åˆ°ä¸æ‡‚çš„åœ°æ–¹å¯ä»¥éšæ—¶é—®æˆ‘",
            "å­¦ä¹ åå¯ä»¥åšç›¸å…³ç»ƒä¹ å·©å›ºçŸ¥è¯†"
        ])
        
        return suggestions[:5]  # è¿”å›å‰5ä¸ªå»ºè®®
    
    def _generate_document_summary(self, document: Dict) -> str:
        """
        ç”Ÿæˆæ–‡æ¡£æ‘˜è¦
        """
        title = document.get('title', 'æœªçŸ¥æ–‡æ¡£')
        category = document.get('category', 'æœªåˆ†ç±»')
        content_preview = document.get('content', '')[:100] + '...' if document.get('content') else 'æš‚æ— å†…å®¹é¢„è§ˆ'
        
        return f"ã€Š{title}ã€‹- {category}ç±»æ–‡æ¡£ã€‚{content_preview}"
    
    def _get_exam_papers_data(self, user_id: str, query: Optional[str] = None) -> List[Dict[str, Any]]:
        """
        è·å–è¯•å·æ•°æ®
        
        Args:
            user_id: ç”¨æˆ·ID
            query: æŸ¥è¯¢å…³é”®è¯ï¼ˆå¯é€‰ï¼‰
        
        Returns:
            è¯•å·æ•°æ®åˆ—è¡¨
        """
        try:
            # æ„å»ºæŸ¥è¯¢
            exam_query = db.session.query(ExamPaper)
            
            if query:
                filters = []
                if hasattr(ExamPaper, 'title'):
                    filters.append(ExamPaper.title.contains(query))
                if hasattr(ExamPaper, 'description'):
                    filters.append(ExamPaper.description.contains(query))
                if hasattr(ExamPaper, 'exam_type'):
                    filters.append(ExamPaper.exam_type.contains(query))
                if hasattr(ExamPaper, 'region'):
                    filters.append(ExamPaper.region.contains(query))
                if filters:
                    exam_query = exam_query.filter(db.or_(*filters))
            
            # é™åˆ¶è¿”å›æ•°é‡
            exam_papers = exam_query.limit(10).all()
            
            papers_data = []
            for paper in exam_papers:
                papers_data.append({
                    'id': paper.id,
                    'title': paper.title,
                    'description': paper.description,
                    'year': paper.year,
                    'exam_type': paper.exam_type,
                    'region': paper.region,
                    'total_score': paper.total_score,
                    'duration': paper.duration,
                    'difficulty_level': paper.difficulty_level,
                    'question_count': paper.question_count,
                    'download_count': paper.download_count
                })
            
            return papers_data
            
        except Exception as e:
            logger.error(f"è·å–è¯•å·æ•°æ®å¤±è´¥: {str(e)}")
            return []
    
    def _get_mistake_records_data(self, user_id: str, query: Optional[str] = None) -> List[Dict[str, Any]]:
        """
        è·å–é”™é¢˜è®°å½•æ•°æ®
        
        Args:
            user_id: ç”¨æˆ·ID
            query: æŸ¥è¯¢å…³é”®è¯ï¼ˆå¯é€‰ï¼‰
        
        Returns:
            é”™é¢˜è®°å½•æ•°æ®åˆ—è¡¨
        """
        try:
            # æ„å»ºæŸ¥è¯¢
            mistake_query = db.session.query(MistakeRecord).filter(
                MistakeRecord.user_id == user_id,
                MistakeRecord.is_archived == False
            )
            
            if query:
                # å…³è”æŸ¥è¯¢é¢˜ç›®å†…å®¹
                from models.question import Question
                mistake_query = mistake_query.join(Question).filter(
                    db.or_(
                        Question.content.contains(query),
                        MistakeRecord.error_analysis.contains(query)
                    )
                )
            
            # æŒ‰æ—¶é—´æ’åºï¼Œé™åˆ¶è¿”å›æ•°é‡
            mistakes = mistake_query.order_by(
                MistakeRecord.created_time.desc()
            ).limit(20).all()
            
            mistakes_data = []
            for mistake in mistakes:
                mistakes_data.append({
                    'id': mistake.id,
                    'question_id': mistake.question_id,
                    'user_answer': mistake.user_answer,
                    'correct_answer': mistake.correct_answer,
                    'mistake_type': mistake.mistake_type.value if hasattr(mistake, 'mistake_type') and mistake.mistake_type is not None else None,
                    'mistake_level': mistake.mistake_level.value if hasattr(mistake, 'mistake_level') and mistake.mistake_level is not None else None,
                    'error_analysis': mistake.error_analysis,
                    'solution_steps': mistake.solution_steps,
                    'key_concepts': mistake.key_concepts,
                    'improvement_suggestions': mistake.improvement_suggestions,
                    'review_count': mistake.review_count,
                    'mastery_level': mistake.mastery_level,
                    'is_resolved': mistake.is_resolved,
                    'priority_score': getattr(mistake, 'priority_score', 0),
                    'created_time': mistake.created_time.isoformat() if hasattr(mistake, 'created_time') and mistake.created_time is not None else None,
                    'next_review_time': mistake.next_review_time.isoformat() if hasattr(mistake, 'next_review_time') and mistake.next_review_time is not None and hasattr(mistake.next_review_time, 'isoformat') else None
                })
            
            return mistakes_data
            
        except Exception as e:
            logger.error(f"è·å–é”™é¢˜è®°å½•å¤±è´¥: {str(e)}")
            return []
    
    def _get_exam_sessions_data(self, user_id: str, query: Optional[str] = None) -> List[Dict[str, Any]]:
        """
        è·å–è€ƒè¯•ä¼šè¯æ•°æ®
        
        Args:
            user_id: ç”¨æˆ·ID
            query: æŸ¥è¯¢å…³é”®è¯ï¼ˆå¯é€‰ï¼‰
        
        Returns:
            è€ƒè¯•ä¼šè¯æ•°æ®åˆ—è¡¨
        """
        try:
            # æ„å»ºæŸ¥è¯¢
            exam_query = db.session.query(ExamSession).filter(
                ExamSession.user_id == user_id
            )
            
            if query:
                filters = []
                if hasattr(ExamSession, 'title'):
                    filters.append(ExamSession.title.contains(query))
                if hasattr(ExamSession, 'description'):
                    filters.append(ExamSession.description.contains(query))
                if hasattr(ExamSession, 'exam_type'):
                    filters.append(ExamSession.exam_type.contains(query))
                if filters:
                    exam_query = exam_query.filter(db.or_(*filters))
            
            # æŒ‰æ—¶é—´æ’åºï¼Œé™åˆ¶è¿”å›æ•°é‡
            exams = exam_query.order_by(
                ExamSession.created_time.desc()
            ).limit(15).all()
            
            exams_data = []
            for exam in exams:
                exams_data.append({
                    'id': exam.id,
                    'title': exam.title,
                    'description': exam.description,
                    'exam_type': exam.exam_type,
                    'status': exam.status,
                    'total_questions': exam.total_questions,
                    'completed_questions': exam.completed_questions,
                    'total_score': exam.total_score,
                    'score_percentage': exam.score_percentage,
                    'correct_answers': exam.correct_answers,
                    'wrong_answers': exam.wrong_answers,
                    'time_efficiency': exam.time_efficiency,
                    'average_time_per_question': exam.average_time_per_question,
                    'created_time': exam.created_time.isoformat() if hasattr(exam, 'created_time') and exam.created_time is not None else None,
                    'actual_start_time': exam.actual_start_time.isoformat() if hasattr(exam, 'actual_start_time') and exam.actual_start_time is not None else None,
                    'end_time': exam.end_time.isoformat() if hasattr(exam, 'end_time') and exam.end_time is not None else None
                })
            
            return exams_data
            
        except Exception as e:
            logger.error(f"è·å–è€ƒè¯•ä¼šè¯æ•°æ®å¤±è´¥: {str(e)}")
            return []
    
    def _get_study_records_data(self, user_id: str, query: Optional[str] = None) -> List[Dict[str, Any]]:
        """
        è·å–å­¦ä¹ è®°å½•æ•°æ®
        
        Args:
            user_id: ç”¨æˆ·ID
            query: æŸ¥è¯¢å…³é”®è¯ï¼ˆå¯é€‰ï¼‰
        
        Returns:
            å­¦ä¹ è®°å½•æ•°æ®åˆ—è¡¨
        """
        try:
            # æ„å»ºæŸ¥è¯¢
            study_query = db.session.query(StudyRecord).filter(
                StudyRecord.user_id == user_id
            )
            
            if query:
                filters = []
                if hasattr(StudyRecord, 'study_type') and hasattr(StudyRecord.study_type.property, 'columns'):
                    filters.append(StudyRecord.study_type.contains(query))
                if hasattr(StudyRecord, 'content_type') and hasattr(StudyRecord.content_type.property, 'columns'):
                    filters.append(StudyRecord.content_type.contains(query))
                if hasattr(StudyRecord, 'notes') and hasattr(StudyRecord.notes.property, 'columns'):
                    filters.append(StudyRecord.notes.contains(query))
                if filters:
                    study_query = study_query.filter(db.or_(*filters))
            
            # æŒ‰æ—¶é—´æ’åºï¼Œé™åˆ¶è¿”å›æ•°é‡
            records = study_query.order_by(
                StudyRecord.start_time.desc()
            ).limit(20).all()
            
            records_data = []
            for record in records:
                records_data.append({
                    'id': record.id,
                    'study_type': record.study_type,
                    'content_type': record.content_type,
                    'is_correct': record.is_correct,
                    'score': record.score,
                    'max_score': record.max_score,
                    'duration': record.duration,
                    'mastery_level': record.mastery_level,
                    'difficulty_rating': record.difficulty_rating,
                    'confidence_level': record.confidence_level,
                    'error_types': record.error_types,
                    'improvement_areas': record.improvement_areas,
                    'notes': record.notes,
                    'start_time': record.start_time.isoformat() if record.start_time else None,
                    'end_time': record.end_time.isoformat() if record.end_time else None
                })
            
            return records_data
            
        except Exception as e:
            logger.error(f"è·å–å­¦ä¹ è®°å½•å¤±è´¥: {str(e)}")
            return []
    
    def _get_learning_analytics_data(self, user_id: str) -> Dict[str, Any]:
        """
        è·å–å­¦ä¹ åˆ†ææ•°æ®
        
        Args:
            user_id: ç”¨æˆ·ID
        
        Returns:
            å­¦ä¹ åˆ†ææ•°æ®
        """
        try:
            from datetime import datetime, timedelta
            from sqlalchemy import func
            
            # è·å–æœ€è¿‘30å¤©çš„æ•°æ®
            thirty_days_ago = datetime.utcnow() - timedelta(days=30)
            
            # é”™é¢˜ç»Ÿè®¡
            mistake_stats = db.session.query(
                func.count(MistakeRecord.id).label('total_mistakes'),
                func.count(func.case((MistakeRecord.is_resolved == True, 1))).label('resolved_mistakes'),
                func.avg(MistakeRecord.mastery_level).label('avg_mastery')
            ).filter(
                MistakeRecord.user_id == user_id
            ).first()
            
            # è€ƒè¯•ç»Ÿè®¡
            exam_stats = db.session.query(
                func.count(ExamSession.id).label('total_exams'),
                func.avg(ExamSession.score_percentage).label('avg_score'),
                func.avg(ExamSession.time_efficiency).label('avg_efficiency')
            ).filter(
                ExamSession.user_id == user_id
            ).filter(
                ExamSession.created_time >= thirty_days_ago
            ).filter(
                ExamSession.status == 'completed' # type: ignore
            ).first()
            
            # å­¦ä¹ æ—¶é•¿ç»Ÿè®¡
            study_stats = db.session.query(
                func.sum(StudyRecord.duration).label('total_duration'),
                func.count(StudyRecord.id).label('total_sessions'),
                func.avg(StudyRecord.mastery_level).label('avg_mastery')
            ).filter(
                StudyRecord.user_id == user_id,
                StudyRecord.start_time >= thirty_days_ago
            ).first()
            
            return {
                'mistake_analysis': {
                    'total_mistakes': getattr(mistake_stats, 'total_mistakes', 0) or 0,
                    'resolved_mistakes': getattr(mistake_stats, 'resolved_mistakes', 0) or 0,
                    'average_mastery': float(getattr(mistake_stats, 'avg_mastery', 0) or 0),
                    'resolution_rate': (getattr(mistake_stats, 'resolved_mistakes', 0) or 0) / max(getattr(mistake_stats, 'total_mistakes', 1) or 1, 1) * 100
                },
                'exam_performance': {
                    'total_exams': getattr(exam_stats, 'total_exams', 0) or 0,
                    'average_score': float(getattr(exam_stats, 'avg_score', 0) or 0),
                    'average_efficiency': float(getattr(exam_stats, 'avg_efficiency', 0) or 0)
                },
                'study_habits': {
                    'total_duration': getattr(study_stats, 'total_duration', 0) or 0,
                    'total_sessions': getattr(study_stats, 'total_sessions', 0) or 0,
                    'average_mastery': float(getattr(study_stats, 'avg_mastery', 0) or 0),
                    'average_session_duration': (getattr(study_stats, 'total_duration', 0) or 0) / max(getattr(study_stats, 'total_sessions', 1) or 1, 1)
                }
            }
            
        except Exception as e:
            logger.error(f"è·å–å­¦ä¹ åˆ†ææ•°æ®å¤±è´¥: {str(e)}")
            return {}
    
    def _should_generate_ppt(self, message: str) -> bool:
        """
        æ£€æµ‹ç”¨æˆ·æ¶ˆæ¯æ˜¯å¦åŒ…å«ç”ŸæˆPPTçš„è¯·æ±‚
        """
        ppt_keywords = [
            'ppt', 'PPT', 'powerpoint', 'PowerPoint', 
            'å¹»ç¯ç‰‡', 'æ¼”ç¤ºæ–‡ç¨¿', 'è¯¾ä»¶', 'ç”Ÿæˆppt', 
            'åˆ¶ä½œppt', 'åˆ›å»ºppt', 'åšä¸ªppt', 'åšä¸€ä¸ªppt'
        ]
        
        message_lower = message.lower()
        return any(keyword.lower() in message_lower for keyword in ppt_keywords)
    
    def _handle_ppt_generation(self, user_id: str, message: str, template_id: Optional[str] = None) -> Dict[str, Any]:
        """
        å¤„ç†PPTç”Ÿæˆè¯·æ±‚
        """
        try:
            # è°ƒç”¨PPTç”ŸæˆæœåŠ¡
            result = ppt_generation_service.generate_ppt_from_text(
                user_id=user_id,
                tenant_id="default",
                content=message,
                title="AIç”Ÿæˆçš„æ¼”ç¤ºæ–‡ç¨¿",
                template_id=template_id
            )
            
            if result['success']:
                data = result['data']
                filename = data['title'] + '.pptx'
                return {
                    "success": True,
                    "response": f"æˆ‘å·²ç»ä¸ºæ‚¨ç”Ÿæˆäº†PPTï¼\n\nğŸ“„ æ–‡ä»¶å: {filename}\nğŸ”— ä¸‹è½½é“¾æ¥: {data['download_url']}\n\nè¯¥PPTå·²è‡ªåŠ¨ä¿å­˜åˆ°æ‚¨çš„æ–‡æ¡£ç®¡ç†ä¸­ï¼Œæ‚¨å¯ä»¥éšæ—¶æŸ¥çœ‹å’Œä¸‹è½½ã€‚",
                    "assistant_name": self.assistant_name,
                    "timestamp": datetime.now().isoformat(),
                    "ppt_info": {
                        "filename": filename,
                        "download_url": data['download_url'],
                        "document_id": data.get('document_id'),
                        "slides_count": data.get('slides_count')
                    },
                    "suggestions": [
                        "æ‚¨å¯ä»¥ç‚¹å‡»ä¸‹è½½é“¾æ¥è·å–PPTæ–‡ä»¶",
                        "PPTå·²ä¿å­˜åœ¨æ–‡æ¡£ç®¡ç†ä¸­ï¼Œå¯éšæ—¶æŸ¥çœ‹",
                        "å¦‚éœ€ä¿®æ”¹PPTå†…å®¹ï¼Œè¯·å‘Šè¯‰æˆ‘å…·ä½“è¦æ±‚"
                    ]
                }
            else:
                return {
                    "success": False,
                    "response": f"æŠ±æ­‰ï¼ŒPPTç”Ÿæˆå¤±è´¥ï¼š{result.get('error', 'æœªçŸ¥é”™è¯¯')}ã€‚è¯·ç¨åé‡è¯•æˆ–æä¾›æ›´è¯¦ç»†çš„å†…å®¹è¦æ±‚ã€‚",
                    "assistant_name": self.assistant_name,
                    "timestamp": datetime.now().isoformat()
                }
                
        except Exception as e:
            logger.error(f"PPTç”Ÿæˆå¤„ç†å¤±è´¥: {str(e)}")
            return {
                "success": False,
                "response": "æŠ±æ­‰ï¼ŒPPTç”ŸæˆåŠŸèƒ½æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åé‡è¯•ã€‚",
                "error": str(e),
                "assistant_name": self.assistant_name,
                "timestamp": datetime.now().isoformat()
            }
    
    def generate_ppt(self, content: str, template_id: Optional[str] = None, 
                    user_id: str = "1", tenant_id: str = "default") -> Dict[str, Any]:
        """
        ç”ŸæˆPPT
        
        Args:
            content: PPTå†…å®¹æè¿°
            template_id: æ¨¡æ¿IDï¼ˆå¯é€‰ï¼‰
            user_id: ç”¨æˆ·ID
            tenant_id: ç§Ÿæˆ·ID
            
        Returns:
            Dict: åŒ…å«ç”Ÿæˆç»“æœçš„å­—å…¸
        """
        try:
            logger.info(f"å¼€å§‹ç”ŸæˆPPTï¼Œç”¨æˆ·ID: {user_id}, æ¨¡æ¿ID: {template_id}")
            
            # è°ƒç”¨PPTç”ŸæˆæœåŠ¡
            result = ppt_generation_service.generate_ppt_from_text(
                content=content,
                user_id=user_id,
                tenant_id=tenant_id,
                template_id=template_id
            )
            
            if result.get('success'):
                logger.info(f"PPTç”ŸæˆæˆåŠŸ: {result.get('filename')}")
                return {
                    "success": True,
                    "filename": result.get('filename'),
                    "download_url": result.get('download_url'),
                    "file_path": result.get('file_path'),
                    "message": "PPTç”ŸæˆæˆåŠŸ"
                }
            else:
                logger.error(f"PPTç”Ÿæˆå¤±è´¥: {result.get('error')}")
                return {
                    "success": False,
                    "message": result.get('error', 'PPTç”Ÿæˆå¤±è´¥'),
                    "error": result.get('error')
                }
                
        except Exception as e:
            logger.error(f"PPTç”Ÿæˆå¼‚å¸¸: {str(e)}")
            return {
                "success": False,
                "message": f"PPTç”Ÿæˆå¤±è´¥: {str(e)}",
                "error": str(e)
            }

# åˆ›å»ºå…¨å±€å®ä¾‹
ai_assistant_service = AIAssistantService()