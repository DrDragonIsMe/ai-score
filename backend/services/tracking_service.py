#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
AIæ™ºèƒ½å­¦ä¹ ç³»ç»Ÿ - ä¸šåŠ¡æœåŠ¡ - tracking_service.py

Description:
    è·Ÿè¸ªæœåŠ¡ï¼Œæä¾›å­¦ä¹ è¡Œä¸ºåˆ†æå’Œç»Ÿè®¡ã€‚

Author: Chang Xinglong
Date: 2025-01-20
Version: 1.0.0
License: Apache License 2.0
"""


import json
import statistics
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Tuple
from sqlalchemy import func, and_, or_
from sqlalchemy.orm import sessionmaker

from models.tracking import (
    LearningMetric, PerformanceSnapshot, LearningReport, GoalTracking, FeedbackRecord
)
from models.user import User
from models.knowledge import Subject
from models.knowledge import KnowledgePoint
from models.question import Question
from models.learning import LearningPath, StudyRecord
from models.learning import MemoryCard
from models.mistake import MistakeRecord
from models.exam import ExamSession
# from services.ai_service import AIService  # æ¨¡å—ä¸å­˜åœ¨ï¼Œæš‚æ—¶æ³¨é‡Š
from utils.database import db
from utils.logger import logger

class TrackingService:
    """
    è¿½è¸ªæœåŠ¡ç±»
    
    æä¾›å­¦ä¹ æ•ˆæœè¿½è¸ªã€æ•°æ®åˆ†æå’ŒæŠ¥å‘Šç”Ÿæˆçš„æ ¸å¿ƒåŠŸèƒ½
    """
    
    def __init__(self):
        pass  # AIService not available
    
    # ==================== æ•°æ®æ”¶é›† ====================
    
    def collect_learning_metrics(self, user_id: int, period_start: datetime, period_end: datetime) -> List[Dict]:
        """
        æ”¶é›†å­¦ä¹ æŒ‡æ ‡æ•°æ®
        
        Args:
            user_id: ç”¨æˆ·ID
            period_start: ç»Ÿè®¡å¼€å§‹æ—¶é—´
            period_end: ç»Ÿè®¡ç»“æŸæ—¶é—´
            
        Returns:
            æŒ‡æ ‡æ•°æ®åˆ—è¡¨
        """
        try:
            metrics = []
            
            # å­¦ä¹ æ—¶é•¿æŒ‡æ ‡
            learning_time = self._collect_learning_time_metrics(user_id, period_start, period_end)
            metrics.extend(learning_time)
            
            # é¢˜ç›®æ•°é‡æŒ‡æ ‡
            question_metrics = self._collect_question_metrics(user_id, period_start, period_end)
            metrics.extend(question_metrics)
            
            # å‡†ç¡®ç‡æŒ‡æ ‡
            accuracy_metrics = self._collect_accuracy_metrics(user_id, period_start, period_end)
            metrics.extend(accuracy_metrics)
            
            # è¿›åº¦æŒ‡æ ‡
            progress_metrics = self._collect_progress_metrics(user_id, period_start, period_end)
            metrics.extend(progress_metrics)
            
            # è®°å¿†ä¿æŒç‡æŒ‡æ ‡
            memory_metrics = self._collect_memory_metrics(user_id, period_start, period_end)
            metrics.extend(memory_metrics)
            
            # è€ƒè¯•è¡¨ç°æŒ‡æ ‡
            exam_metrics = self._collect_exam_metrics(user_id, period_start, period_end)
            metrics.extend(exam_metrics)
            
            # é”™è¯¯å‡å°‘ç‡æŒ‡æ ‡
            mistake_metrics = self._collect_mistake_metrics(user_id, period_start, period_end)
            metrics.extend(mistake_metrics)
            
            return metrics
            
        except Exception as e:
            logger.error(f"æ”¶é›†å­¦ä¹ æŒ‡æ ‡å¤±è´¥: {str(e)}")
            return []
    
    def _collect_learning_time_metrics(self, user_id: int, period_start: datetime, period_end: datetime) -> List[Dict]:
        """æ”¶é›†å­¦ä¹ æ—¶é•¿æŒ‡æ ‡"""
        metrics = []
        
        # æ€»å­¦ä¹ æ—¶é•¿
        total_time = db.session.query(func.sum(LearningSession.duration_minutes)).filter(
            LearningSession.user_id == user_id,
            LearningSession.start_time >= period_start,
            LearningSession.start_time <= period_end
        ).scalar() or 0
        
        metrics.append({
            'metric_type': MetricType.LEARNING_TIME.value,
            'metric_name': 'æ€»å­¦ä¹ æ—¶é•¿',
            'metric_value': total_time,
            'metric_unit': 'åˆ†é’Ÿ'
        })
        
        # å¹³å‡æ¯æ—¥å­¦ä¹ æ—¶é•¿
        days = (period_end - period_start).days + 1
        avg_daily_time = total_time / days if days > 0 else 0
        
        metrics.append({
            'metric_type': MetricType.LEARNING_TIME.value,
            'metric_name': 'å¹³å‡æ¯æ—¥å­¦ä¹ æ—¶é•¿',
            'metric_value': avg_daily_time,
            'metric_unit': 'åˆ†é’Ÿ'
        })
        
        # æŒ‰å­¦ç§‘ç»Ÿè®¡å­¦ä¹ æ—¶é•¿
        subject_times = db.session.query(
            Subject.name,
            func.sum(LearningSession.duration_minutes)
        ).join(LearningSession).filter(
            LearningSession.user_id == user_id,
            LearningSession.start_time >= period_start,
            LearningSession.start_time <= period_end
        ).group_by(Subject.id).all()
        
        for subject_name, subject_time in subject_times:
            metrics.append({
                'metric_type': MetricType.LEARNING_TIME.value,
                'metric_name': f'{subject_name}å­¦ä¹ æ—¶é•¿',
                'metric_value': subject_time or 0,
                'metric_unit': 'åˆ†é’Ÿ',
                'context_data': {'subject': subject_name}
            })
        
        return metrics
    
    def _collect_question_metrics(self, user_id: int, period_start: datetime, period_end: datetime) -> List[Dict]:
        """æ”¶é›†é¢˜ç›®æ•°é‡æŒ‡æ ‡"""
        metrics = []
        
        # æ€»ç­”é¢˜æ•°
        total_questions = db.session.query(func.count(UserAnswer.id)).filter(
            UserAnswer.user_id == user_id,
            UserAnswer.created_time >= period_start,
            UserAnswer.created_time <= period_end
        ).scalar() or 0
        
        metrics.append({
            'metric_type': MetricType.QUESTION_COUNT.value,
            'metric_name': 'æ€»ç­”é¢˜æ•°',
            'metric_value': total_questions,
            'metric_unit': 'é¢˜'
        })
        
        # æŒ‰éš¾åº¦ç»Ÿè®¡ç­”é¢˜æ•°
        difficulty_counts = db.session.query(
            Question.difficulty_level,
            func.count(UserAnswer.id)
        ).join(UserAnswer).filter(
            UserAnswer.user_id == user_id,
            UserAnswer.created_time >= period_start,
            UserAnswer.created_time <= period_end
        ).group_by(Question.difficulty_level).all()
        
        for difficulty, count in difficulty_counts:
            metrics.append({
                'metric_type': MetricType.QUESTION_COUNT.value,
                'metric_name': f'{difficulty}éš¾åº¦ç­”é¢˜æ•°',
                'metric_value': count,
                'metric_unit': 'é¢˜',
                'context_data': {'difficulty': difficulty}
            })
        
        return metrics
    
    def _collect_accuracy_metrics(self, user_id: int, period_start: datetime, period_end: datetime) -> List[Dict]:
        """æ”¶é›†å‡†ç¡®ç‡æŒ‡æ ‡"""
        metrics = []
        
        # æ€»ä½“å‡†ç¡®ç‡
        total_answers = db.session.query(func.count(UserAnswer.id)).filter(
            UserAnswer.user_id == user_id,
            UserAnswer.created_time >= period_start,
            UserAnswer.created_time <= period_end
        ).scalar() or 0
        
        correct_answers = db.session.query(func.count(UserAnswer.id)).filter(
            UserAnswer.user_id == user_id,
            UserAnswer.is_correct == True,
            UserAnswer.created_time >= period_start,
            UserAnswer.created_time <= period_end
        ).scalar() or 0
        
        overall_accuracy = (correct_answers / total_answers * 100) if total_answers > 0 else 0
        
        metrics.append({
            'metric_type': MetricType.ACCURACY_RATE.value,
            'metric_name': 'æ€»ä½“å‡†ç¡®ç‡',
            'metric_value': overall_accuracy,
            'metric_unit': '%'
        })
        
        # æŒ‰å­¦ç§‘ç»Ÿè®¡å‡†ç¡®ç‡
        subject_accuracy = db.session.query(
            Subject.name,
            func.count(UserAnswer.id).label('total'),
            func.sum(func.cast(UserAnswer.is_correct, db.Integer)).label('correct')
        ).join(Question).join(UserAnswer).filter(
            UserAnswer.user_id == user_id,
            UserAnswer.created_time >= period_start,
            UserAnswer.created_time <= period_end
        ).group_by(Subject.id).all()
        
        for subject_name, total, correct in subject_accuracy:
            accuracy = (correct / total * 100) if total > 0 else 0
            metrics.append({
                'metric_type': MetricType.ACCURACY_RATE.value,
                'metric_name': f'{subject_name}å‡†ç¡®ç‡',
                'metric_value': accuracy,
                'metric_unit': '%',
                'context_data': {'subject': subject_name}
            })
        
        return metrics
    
    def _collect_progress_metrics(self, user_id: int, period_start: datetime, period_end: datetime) -> List[Dict]:
        """æ”¶é›†è¿›åº¦æŒ‡æ ‡"""
        metrics = []
        
        # çŸ¥è¯†ç‚¹æŒæ¡è¿›åº¦
        progress_records = db.session.query(LearningProgress).filter(
            LearningProgress.user_id == user_id,
            LearningProgress.updated_time >= period_start,
            LearningProgress.updated_time <= period_end
        ).all()
        
        if progress_records:
            avg_mastery = statistics.mean([p.mastery_level for p in progress_records])
            metrics.append({
                'metric_type': MetricType.KNOWLEDGE_MASTERY.value,
                'metric_name': 'å¹³å‡çŸ¥è¯†æŒæ¡åº¦',
                'metric_value': avg_mastery * 100,
                'metric_unit': '%'
            })
        
        return metrics
    
    def _collect_memory_metrics(self, user_id: int, period_start: datetime, period_end: datetime) -> List[Dict]:
        """æ”¶é›†è®°å¿†ä¿æŒç‡æŒ‡æ ‡"""
        metrics = []
        
        # å¤ä¹ è®°å½•ç»Ÿè®¡
        review_records = db.session.query(ReviewRecord).filter(
            ReviewRecord.user_id == user_id,
            ReviewRecord.review_time >= period_start,
            ReviewRecord.review_time <= period_end
        ).all()
        
        if review_records:
            # è®°å¿†ä¿æŒç‡
            correct_reviews = sum(1 for r in review_records if r.is_correct)
            retention_rate = (correct_reviews / len(review_records) * 100) if review_records else 0
            
            metrics.append({
                'metric_type': MetricType.MEMORY_RETENTION.value,
                'metric_name': 'è®°å¿†ä¿æŒç‡',
                'metric_value': retention_rate,
                'metric_unit': '%'
            })
        
        return metrics
    
    def _collect_exam_metrics(self, user_id: int, period_start: datetime, period_end: datetime) -> List[Dict]:
        """æ”¶é›†è€ƒè¯•è¡¨ç°æŒ‡æ ‡"""
        metrics = []
        
        # è€ƒè¯•æˆç»©ç»Ÿè®¡
        exam_sessions = db.session.query(ExamSession).filter(
            ExamSession.user_id == user_id,
            ExamSession.start_time >= period_start,
            ExamSession.start_time <= period_end,
            ExamSession.status == 'completed'
        ).all()
        
        if exam_sessions:
            avg_score = statistics.mean([e.final_score for e in exam_sessions if e.final_score])
            metrics.append({
                'metric_type': MetricType.EXAM_PERFORMANCE.value,
                'metric_name': 'å¹³å‡è€ƒè¯•æˆç»©',
                'metric_value': avg_score,
                'metric_unit': 'åˆ†'
            })
        
        return metrics
    
    def _collect_mistake_metrics(self, user_id: int, period_start: datetime, period_end: datetime) -> List[Dict]:
        """æ”¶é›†é”™è¯¯å‡å°‘ç‡æŒ‡æ ‡"""
        metrics = []
        
        # é”™é¢˜è®°å½•ç»Ÿè®¡
        mistake_count = db.session.query(func.count(MistakeRecord.id)).filter(
            MistakeRecord.user_id == user_id,
            MistakeRecord.created_time >= period_start,
            MistakeRecord.created_time <= period_end
        ).scalar() or 0
        
        # è®¡ç®—é”™è¯¯å‡å°‘ç‡ï¼ˆéœ€è¦å¯¹æ¯”å‰ä¸€ä¸ªå‘¨æœŸï¼‰
        prev_period_start = period_start - (period_end - period_start)
        prev_mistake_count = db.session.query(func.count(MistakeRecord.id)).filter(
            MistakeRecord.user_id == user_id,
            MistakeRecord.created_time >= prev_period_start,
            MistakeRecord.created_time < period_start
        ).scalar() or 0
        
        if prev_mistake_count > 0:
            reduction_rate = ((prev_mistake_count - mistake_count) / prev_mistake_count * 100)
        else:
            reduction_rate = 0
        
        metrics.append({
            'metric_type': MetricType.MISTAKE_REDUCTION.value,
            'metric_name': 'é”™è¯¯å‡å°‘ç‡',
            'metric_value': reduction_rate,
            'metric_unit': '%'
        })
        
        return metrics
    
    def save_learning_metrics(self, user_id: int, tenant_id: int, metrics: List[Dict], 
                            period_type: str, period_start: datetime, period_end: datetime) -> List[LearningMetric]:
        """
        ä¿å­˜å­¦ä¹ æŒ‡æ ‡æ•°æ®
        
        Args:
            user_id: ç”¨æˆ·ID
            tenant_id: ç§Ÿæˆ·ID
            metrics: æŒ‡æ ‡æ•°æ®åˆ—è¡¨
            period_type: å‘¨æœŸç±»å‹
            period_start: å‘¨æœŸå¼€å§‹æ—¶é—´
            period_end: å‘¨æœŸç»“æŸæ—¶é—´
            
        Returns:
            ä¿å­˜çš„æŒ‡æ ‡è®°å½•åˆ—è¡¨
        """
        try:
            saved_metrics = []
            
            for metric_data in metrics:
                metric = LearningMetric(
                    user_id=user_id,
                    tenant_id=tenant_id,
                    metric_type=metric_data['metric_type'],
                    metric_name=metric_data['metric_name'],
                    metric_value=metric_data['metric_value'],
                    metric_unit=metric_data.get('metric_unit'),
                    subject_id=metric_data.get('subject_id'),
                    knowledge_point_id=metric_data.get('knowledge_point_id'),
                    difficulty_level=metric_data.get('difficulty_level'),
                    period_type=period_type,
                    period_start=period_start,
                    period_end=period_end,
                    context_data=metric_data.get('context_data'),
                    tags=metric_data.get('tags')
                )
                
                db.session.add(metric)
                saved_metrics.append(metric)
            
            db.session.commit()
            return saved_metrics
            
        except Exception as e:
            db.session.rollback()
            logger.error(f"ä¿å­˜å­¦ä¹ æŒ‡æ ‡å¤±è´¥: {str(e)}")
            return []
    
    # ==================== æ€§èƒ½å¿«ç…§ ====================
    
    def create_performance_snapshot(self, user_id: int, tenant_id: int, period_type: str, 
                                  period_start: datetime, period_end: datetime) -> Optional[PerformanceSnapshot]:
        """
        åˆ›å»ºæ€§èƒ½å¿«ç…§
        
        Args:
            user_id: ç”¨æˆ·ID
            tenant_id: ç§Ÿæˆ·ID
            period_type: å‘¨æœŸç±»å‹
            period_start: å‘¨æœŸå¼€å§‹æ—¶é—´
            period_end: å‘¨æœŸç»“æŸæ—¶é—´
            
        Returns:
            æ€§èƒ½å¿«ç…§å¯¹è±¡
        """
        try:
            # æ”¶é›†æŒ‡æ ‡æ•°æ®
            metrics = self.collect_learning_metrics(user_id, period_start, period_end)
            
            # è®¡ç®—ç»¼åˆæŒ‡æ ‡
            overall_score = self._calculate_overall_score(metrics)
            learning_efficiency = self._calculate_learning_efficiency(metrics)
            knowledge_growth = self._calculate_knowledge_growth(user_id, period_start, period_end)
            skill_improvement = self._calculate_skill_improvement(user_id, period_start, period_end)
            
            # åˆ†é¡¹æŒ‡æ ‡
            time_metrics = self._extract_time_metrics(metrics)
            accuracy_metrics = self._extract_accuracy_metrics(metrics)
            progress_metrics = self._extract_progress_metrics(metrics)
            engagement_metrics = self._calculate_engagement_metrics(user_id, period_start, period_end)
            
            # å­¦ç§‘è¡¨ç°
            subject_performance = self._calculate_subject_performance(user_id, period_start, period_end)
            
            # è·å–ä¸Šä¸€ä¸ªå¿«ç…§
            previous_snapshot = db.session.query(PerformanceSnapshot).filter(
                PerformanceSnapshot.user_id == user_id,
                PerformanceSnapshot.period_type == period_type,
                PerformanceSnapshot.snapshot_date < period_end
            ).order_by(PerformanceSnapshot.snapshot_date.desc()).first()
            
            # è®¡ç®—æ”¹è¿›ç‡
            improvement_rate = None
            if previous_snapshot and previous_snapshot.overall_score:
                improvement_rate = (overall_score - previous_snapshot.overall_score) / previous_snapshot.overall_score
            
            # é¢„æµ‹ä¸‹æœŸå¾—åˆ†
            predicted_score, confidence = self._predict_next_performance(user_id, overall_score, improvement_rate)
            
            # åˆ›å»ºå¿«ç…§
            snapshot = PerformanceSnapshot(
                user_id=user_id,
                tenant_id=tenant_id,
                period_type=period_type,
                period_start=period_start,
                period_end=period_end,
                overall_score=overall_score,
                learning_efficiency=learning_efficiency,
                knowledge_growth=knowledge_growth,
                skill_improvement=skill_improvement,
                time_metrics=time_metrics,
                accuracy_metrics=accuracy_metrics,
                progress_metrics=progress_metrics,
                engagement_metrics=engagement_metrics,
                subject_performance=subject_performance,
                previous_snapshot_id=previous_snapshot.id if previous_snapshot else None,
                improvement_rate=improvement_rate,
                predicted_next_score=predicted_score,
                confidence_level=confidence
            )
            
            db.session.add(snapshot)
            db.session.commit()
            
            return snapshot
            
        except Exception as e:
            db.session.rollback()
            logger.error(f"åˆ›å»ºæ€§èƒ½å¿«ç…§å¤±è´¥: {str(e)}")
            return None
    
    def _calculate_overall_score(self, metrics: List[Dict]) -> float:
        """è®¡ç®—ç»¼åˆå¾—åˆ†"""
        if not metrics:
            return 0.0
        
        # æƒé‡é…ç½®
        weights = {
            MetricType.ACCURACY_RATE.value: 0.3,
            MetricType.LEARNING_TIME.value: 0.2,
            MetricType.KNOWLEDGE_MASTERY.value: 0.2,
            MetricType.MEMORY_RETENTION.value: 0.15,
            MetricType.EXAM_PERFORMANCE.value: 0.15
        }
        
        weighted_sum = 0.0
        total_weight = 0.0
        
        for metric in metrics:
            metric_type = metric['metric_type']
            if metric_type in weights:
                # æ ‡å‡†åŒ–æŒ‡æ ‡å€¼åˆ°0-100èŒƒå›´
                normalized_value = self._normalize_metric_value(metric)
                weighted_sum += normalized_value * weights[metric_type]
                total_weight += weights[metric_type]
        
        return weighted_sum / total_weight if total_weight > 0 else 0.0
    
    def _normalize_metric_value(self, metric: Dict) -> float:
        """æ ‡å‡†åŒ–æŒ‡æ ‡å€¼"""
        metric_type = metric['metric_type']
        value = metric['metric_value']
        
        if metric_type == MetricType.ACCURACY_RATE.value:
            return min(100, max(0, value))  # å·²ç»æ˜¯ç™¾åˆ†æ¯”
        elif metric_type == MetricType.LEARNING_TIME.value:
            # å­¦ä¹ æ—¶é•¿ï¼šå‡è®¾æ¯æ—¥2å°æ—¶ä¸ºæ»¡åˆ†
            if 'æ¯æ—¥' in metric['metric_name']:
                return min(100, (value / 120) * 100)
            else:
                return min(100, (value / 3600) * 100)  # æœˆåº¦æ€»æ—¶é•¿
        elif metric_type in [MetricType.KNOWLEDGE_MASTERY.value, MetricType.MEMORY_RETENTION.value]:
            return min(100, max(0, value))  # å·²ç»æ˜¯ç™¾åˆ†æ¯”
        elif metric_type == MetricType.EXAM_PERFORMANCE.value:
            return min(100, max(0, value))  # è€ƒè¯•åˆ†æ•°
        else:
            return value
    
    def _calculate_learning_efficiency(self, metrics: List[Dict]) -> float:
        """è®¡ç®—å­¦ä¹ æ•ˆç‡"""
        # å­¦ä¹ æ•ˆç‡ = å‡†ç¡®ç‡ / å­¦ä¹ æ—¶é•¿ï¼ˆæ ‡å‡†åŒ–ï¼‰
        accuracy = 0
        time_spent = 0
        
        for metric in metrics:
            if metric['metric_type'] == MetricType.ACCURACY_RATE.value and 'æ€»ä½“' in metric['metric_name']:
                accuracy = metric['metric_value']
            elif metric['metric_type'] == MetricType.LEARNING_TIME.value and 'å¹³å‡æ¯æ—¥' in metric['metric_name']:
                time_spent = metric['metric_value']
        
        if time_spent > 0:
            efficiency = (accuracy / 100) * (120 / max(time_spent, 30))  # æ ‡å‡†åŒ–åˆ°2å°æ—¶
            return min(1.0, efficiency)
        
        return 0.0
    
    def _calculate_knowledge_growth(self, user_id: int, period_start: datetime, period_end: datetime) -> float:
        """è®¡ç®—çŸ¥è¯†å¢é•¿ç‡"""
        # æ¯”è¾ƒæœŸåˆæœŸæœ«çš„çŸ¥è¯†æŒæ¡åº¦
        start_mastery = db.session.query(func.avg(LearningProgress.mastery_level)).filter(
            LearningProgress.user_id == user_id,
            LearningProgress.updated_time <= period_start
        ).scalar() or 0
        
        end_mastery = db.session.query(func.avg(LearningProgress.mastery_level)).filter(
            LearningProgress.user_id == user_id,
            LearningProgress.updated_time <= period_end
        ).scalar() or 0
        
        if start_mastery > 0:
            growth = (end_mastery - start_mastery) / start_mastery
            return max(0, min(1, growth))
        
        return 0.0
    
    def _calculate_skill_improvement(self, user_id: int, period_start: datetime, period_end: datetime) -> float:
        """è®¡ç®—æŠ€èƒ½æå‡åº¦"""
        # åŸºäºç­”é¢˜å‡†ç¡®ç‡çš„æå‡
        period_duration = period_end - period_start
        mid_point = period_start + period_duration / 2
        
        # å‰åŠæœŸå‡†ç¡®ç‡
        early_accuracy = self._get_accuracy_for_period(user_id, period_start, mid_point)
        # ååŠæœŸå‡†ç¡®ç‡
        late_accuracy = self._get_accuracy_for_period(user_id, mid_point, period_end)
        
        if early_accuracy > 0:
            improvement = (late_accuracy - early_accuracy) / early_accuracy
            return max(0, min(1, improvement))
        
        return 0.0
    
    def _get_accuracy_for_period(self, user_id: int, start_time: datetime, end_time: datetime) -> float:
        """è·å–æŒ‡å®šæ—¶æœŸçš„å‡†ç¡®ç‡"""
        total = db.session.query(func.count(UserAnswer.id)).filter(
            UserAnswer.user_id == user_id,
            UserAnswer.created_time >= start_time,
            UserAnswer.created_time <= end_time
        ).scalar() or 0
        
        correct = db.session.query(func.count(UserAnswer.id)).filter(
            UserAnswer.user_id == user_id,
            UserAnswer.is_correct == True,
            UserAnswer.created_time >= start_time,
            UserAnswer.created_time <= end_time
        ).scalar() or 0
        
        return (correct / total * 100) if total > 0 else 0
    
    def _extract_time_metrics(self, metrics: List[Dict]) -> Dict:
        """æå–æ—¶é—´ç›¸å…³æŒ‡æ ‡"""
        time_metrics = {}
        for metric in metrics:
            if metric['metric_type'] == MetricType.LEARNING_TIME.value:
                time_metrics[metric['metric_name']] = {
                    'value': metric['metric_value'],
                    'unit': metric['metric_unit']
                }
        return time_metrics
    
    def _extract_accuracy_metrics(self, metrics: List[Dict]) -> Dict:
        """æå–å‡†ç¡®ç‡ç›¸å…³æŒ‡æ ‡"""
        accuracy_metrics = {}
        for metric in metrics:
            if metric['metric_type'] == MetricType.ACCURACY_RATE.value:
                accuracy_metrics[metric['metric_name']] = {
                    'value': metric['metric_value'],
                    'unit': metric['metric_unit']
                }
        return accuracy_metrics
    
    def _extract_progress_metrics(self, metrics: List[Dict]) -> Dict:
        """æå–è¿›åº¦ç›¸å…³æŒ‡æ ‡"""
        progress_metrics = {}
        for metric in metrics:
            if metric['metric_type'] in [MetricType.KNOWLEDGE_MASTERY.value, MetricType.PROGRESS_SCORE.value]:
                progress_metrics[metric['metric_name']] = {
                    'value': metric['metric_value'],
                    'unit': metric['metric_unit']
                }
        return progress_metrics
    
    def _calculate_engagement_metrics(self, user_id: int, period_start: datetime, period_end: datetime) -> Dict:
        """è®¡ç®—å‚ä¸åº¦æŒ‡æ ‡"""
        # å­¦ä¹ å¤©æ•°
        learning_days = db.session.query(func.count(func.distinct(func.date(LearningSession.start_time)))).filter(
            LearningSession.user_id == user_id,
            LearningSession.start_time >= period_start,
            LearningSession.start_time <= period_end
        ).scalar() or 0
        
        total_days = (period_end - period_start).days + 1
        engagement_rate = (learning_days / total_days * 100) if total_days > 0 else 0
        
        # å¹³å‡ä¼šè¯æ—¶é•¿
        avg_session_duration = db.session.query(func.avg(LearningSession.duration_minutes)).filter(
            LearningSession.user_id == user_id,
            LearningSession.start_time >= period_start,
            LearningSession.start_time <= period_end
        ).scalar() or 0
        
        return {
            'learning_days': learning_days,
            'total_days': total_days,
            'engagement_rate': engagement_rate,
            'avg_session_duration': avg_session_duration
        }
    
    def _calculate_subject_performance(self, user_id: int, period_start: datetime, period_end: datetime) -> Dict:
        """è®¡ç®—å­¦ç§‘è¡¨ç°"""
        subject_performance = {}
        
        subjects = db.session.query(Subject).all()
        for subject in subjects:
            # è¯¥å­¦ç§‘çš„å‡†ç¡®ç‡
            accuracy = self._get_subject_accuracy(user_id, subject.id, period_start, period_end)
            
            # è¯¥å­¦ç§‘çš„å­¦ä¹ æ—¶é•¿
            learning_time = db.session.query(func.sum(LearningSession.duration_minutes)).filter(
                LearningSession.user_id == user_id,
                LearningSession.subject_id == subject.id,
                LearningSession.start_time >= period_start,
                LearningSession.start_time <= period_end
            ).scalar() or 0
            
            # è¯¥å­¦ç§‘çš„é¢˜ç›®æ•°é‡
            question_count = db.session.query(func.count(UserAnswer.id)).join(Question).filter(
                UserAnswer.user_id == user_id,
                Question.subject_id == subject.id,
                UserAnswer.created_time >= period_start,
                UserAnswer.created_time <= period_end
            ).scalar() or 0
            
            subject_performance[subject.name] = {
                'accuracy': accuracy,
                'learning_time': learning_time,
                'question_count': question_count,
                'score': (accuracy + min(100, learning_time/10) + min(100, question_count)) / 3
            }
        
        return subject_performance
    
    def _get_subject_accuracy(self, user_id: int, subject_id: int, period_start: datetime, period_end: datetime) -> float:
        """è·å–å­¦ç§‘å‡†ç¡®ç‡"""
        total = db.session.query(func.count(UserAnswer.id)).join(Question).filter(
            UserAnswer.user_id == user_id,
            Question.subject_id == subject_id,
            UserAnswer.created_time >= period_start,
            UserAnswer.created_time <= period_end
        ).scalar() or 0
        
        correct = db.session.query(func.count(UserAnswer.id)).join(Question).filter(
            UserAnswer.user_id == user_id,
            Question.subject_id == subject_id,
            UserAnswer.is_correct == True,
            UserAnswer.created_time >= period_start,
            UserAnswer.created_time <= period_end
        ).scalar() or 0
        
        return (correct / total * 100) if total > 0 else 0
    
    def _predict_next_performance(self, user_id: int, current_score: float, improvement_rate: Optional[float]) -> Tuple[float, float]:
        """é¢„æµ‹ä¸‹æœŸè¡¨ç°"""
        # ç®€å•çš„çº¿æ€§é¢„æµ‹æ¨¡å‹
        if improvement_rate is not None:
            predicted_score = current_score * (1 + improvement_rate)
            confidence = 0.7  # åŸºç¡€ç½®ä¿¡åº¦
            
            # æ ¹æ®å†å²æ•°æ®è°ƒæ•´ç½®ä¿¡åº¦
            historical_snapshots = db.session.query(PerformanceSnapshot).filter(
                PerformanceSnapshot.user_id == user_id
            ).order_by(PerformanceSnapshot.snapshot_date.desc()).limit(5).all()
            
            if len(historical_snapshots) >= 3:
                # å¦‚æœè¶‹åŠ¿ç¨³å®šï¼Œæé«˜ç½®ä¿¡åº¦
                recent_improvements = [s.improvement_rate for s in historical_snapshots if s.improvement_rate is not None]
                if recent_improvements:
                    variance = statistics.variance(recent_improvements) if len(recent_improvements) > 1 else 0
                    confidence = max(0.5, min(0.9, 0.7 - variance))
        else:
            predicted_score = current_score
            confidence = 0.5
        
        return min(100, max(0, predicted_score)), confidence
    
    # ==================== æŠ¥å‘Šç”Ÿæˆ ====================
    
    def generate_learning_report(self, user_id: int, tenant_id: int, report_type: str, 
                               period_start: datetime, period_end: datetime) -> Optional[LearningReport]:
        """
        ç”Ÿæˆå­¦ä¹ æŠ¥å‘Š
        
        Args:
            user_id: ç”¨æˆ·ID
            tenant_id: ç§Ÿæˆ·ID
            report_type: æŠ¥å‘Šç±»å‹
            period_start: æŠ¥å‘Šå‘¨æœŸå¼€å§‹æ—¶é—´
            period_end: æŠ¥å‘Šå‘¨æœŸç»“æŸæ—¶é—´
            
        Returns:
            å­¦ä¹ æŠ¥å‘Šå¯¹è±¡
        """
        try:
            # è·å–ç”¨æˆ·ä¿¡æ¯
            user = db.session.query(User).filter(User.id == user_id).first()
            if not user:
                return None
            
            # ç”ŸæˆæŠ¥å‘Šæ ‡é¢˜
            report_title = self._generate_report_title(report_type, period_start, period_end)
            
            # è·å–æ€§èƒ½å¿«ç…§
            snapshot = db.session.query(PerformanceSnapshot).filter(
                PerformanceSnapshot.user_id == user_id,
                PerformanceSnapshot.period_start == period_start,
                PerformanceSnapshot.period_end == period_end
            ).first()
            
            if not snapshot:
                # å¦‚æœæ²¡æœ‰å¿«ç…§ï¼Œå…ˆåˆ›å»ºä¸€ä¸ª
                period_type = self._determine_period_type(period_start, period_end)
                snapshot = self.create_performance_snapshot(user_id, tenant_id, period_type, period_start, period_end)
            
            if not snapshot:
                return None
            
            # ç”ŸæˆæŠ¥å‘Šå†…å®¹
            summary = self._generate_report_summary(user, snapshot, report_type)
            key_insights = self._generate_key_insights(snapshot)
            performance_data = self._prepare_performance_data(snapshot)
            trend_analysis = self._generate_trend_analysis(user_id, snapshot)
            achievements = self._identify_achievements(snapshot)
            areas_for_improvement = self._identify_improvement_areas(snapshot)
            recommendations = self._generate_recommendations(snapshot)
            charts_data = self._prepare_charts_data(snapshot)
            
            # åˆ›å»ºæŠ¥å‘Š
            report = LearningReport(
                user_id=user_id,
                tenant_id=tenant_id,
                report_type=report_type,
                report_title=report_title,
                report_period=self._determine_period_type(period_start, period_end),
                period_start=period_start,
                period_end=period_end,
                summary=summary,
                key_insights=key_insights,
                performance_data=performance_data,
                trend_analysis=trend_analysis,
                achievements=achievements,
                areas_for_improvement=areas_for_improvement,
                recommendations=recommendations,
                charts_data=charts_data,
                recipients=[{'type': 'student', 'id': user_id, 'name': user.username}]
            )
            
            db.session.add(report)
            db.session.commit()
            
            # æ ‡è®°ä¸ºå·²ç”Ÿæˆ
            report.mark_as_generated()
            db.session.commit()
            
            return report
            
        except Exception as e:
            db.session.rollback()
            logger.error(f"ç”Ÿæˆå­¦ä¹ æŠ¥å‘Šå¤±è´¥: {str(e)}")
            return None
    
    def _generate_report_title(self, report_type: str, period_start: datetime, period_end: datetime) -> str:
        """ç”ŸæˆæŠ¥å‘Šæ ‡é¢˜"""
        period_str = f"{period_start.strftime('%Yå¹´%mæœˆ%dæ—¥')} è‡³ {period_end.strftime('%Yå¹´%mæœˆ%dæ—¥')}"
        
        title_map = {
            ReportType.DAILY_SUMMARY.value: f"æ¯æ—¥å­¦ä¹ æ€»ç»“ - {period_str}",
            ReportType.WEEKLY_REPORT.value: f"å‘¨åº¦å­¦ä¹ æŠ¥å‘Š - {period_str}",
            ReportType.MONTHLY_REPORT.value: f"æœˆåº¦å­¦ä¹ æŠ¥å‘Š - {period_str}",
            ReportType.PROGRESS_REPORT.value: f"å­¦ä¹ è¿›åº¦æŠ¥å‘Š - {period_str}",
            ReportType.PERFORMANCE_ANALYSIS.value: f"å­¦ä¹ è¡¨ç°åˆ†æ - {period_str}",
            ReportType.IMPROVEMENT_SUGGESTION.value: f"å­¦ä¹ æ”¹è¿›å»ºè®® - {period_str}"
        }
        
        return title_map.get(report_type, f"å­¦ä¹ æŠ¥å‘Š - {period_str}")
    
    def _determine_period_type(self, period_start: datetime, period_end: datetime) -> str:
        """ç¡®å®šå‘¨æœŸç±»å‹"""
        duration = period_end - period_start
        
        if duration.days <= 1:
            return TrackingPeriod.DAILY.value
        elif duration.days <= 7:
            return TrackingPeriod.WEEKLY.value
        elif duration.days <= 31:
            return TrackingPeriod.MONTHLY.value
        elif duration.days <= 93:
            return TrackingPeriod.QUARTERLY.value
        else:
            return TrackingPeriod.YEARLY.value
    
    def _generate_report_summary(self, user: User, snapshot: PerformanceSnapshot, report_type: str) -> str:
        """ç”ŸæˆæŠ¥å‘Šæ‘˜è¦"""
        summary_parts = [
            f"äº²çˆ±çš„{user.username}ï¼Œ",
            f"åœ¨æœ¬æŠ¥å‘Šå‘¨æœŸå†…ï¼Œæ‚¨çš„ç»¼åˆå­¦ä¹ è¡¨ç°å¾—åˆ†ä¸º{snapshot.overall_score:.1f}åˆ†ã€‚"
        ]
        
        if snapshot.improvement_rate is not None:
            if snapshot.improvement_rate > 0:
                summary_parts.append(f"ç›¸æ¯”ä¸Šä¸€å‘¨æœŸï¼Œæ‚¨çš„è¡¨ç°æå‡äº†{snapshot.improvement_rate*100:.1f}%ï¼Œç»§ç»­ä¿æŒï¼")
            elif snapshot.improvement_rate < 0:
                summary_parts.append(f"ç›¸æ¯”ä¸Šä¸€å‘¨æœŸï¼Œæ‚¨çš„è¡¨ç°ä¸‹é™äº†{abs(snapshot.improvement_rate)*100:.1f}%ï¼Œéœ€è¦åŠ æ²¹å“¦ï¼")
            else:
                summary_parts.append("æ‚¨çš„è¡¨ç°ä¿æŒç¨³å®šã€‚")
        
        # æ·»åŠ å­¦ä¹ æ•ˆç‡è¯„ä»·
        if snapshot.learning_efficiency > 0.8:
            summary_parts.append("æ‚¨çš„å­¦ä¹ æ•ˆç‡å¾ˆé«˜ï¼Œèƒ½å¤Ÿåœ¨è¾ƒçŸ­æ—¶é—´å†…å–å¾—è‰¯å¥½æ•ˆæœã€‚")
        elif snapshot.learning_efficiency > 0.6:
            summary_parts.append("æ‚¨çš„å­¦ä¹ æ•ˆç‡ä¸­ç­‰ï¼Œè¿˜æœ‰æå‡ç©ºé—´ã€‚")
        else:
            summary_parts.append("å»ºè®®ä¼˜åŒ–å­¦ä¹ æ–¹æ³•ï¼Œæé«˜å­¦ä¹ æ•ˆç‡ã€‚")
        
        return " ".join(summary_parts)
    
    def _generate_key_insights(self, snapshot: PerformanceSnapshot) -> List[Dict]:
        """ç”Ÿæˆå…³é”®æ´å¯Ÿ"""
        insights = []
        
        # æœ€å¼ºå­¦ç§‘
        if snapshot.subject_performance:
            best_subject = max(snapshot.subject_performance.items(), key=lambda x: x[1]['score'])
            insights.append({
                'type': 'strength',
                'title': 'æœ€å¼ºå­¦ç§‘',
                'content': f"{best_subject[0]}æ˜¯æ‚¨çš„å¼ºé¡¹ï¼Œå‡†ç¡®ç‡è¾¾åˆ°{best_subject[1]['accuracy']:.1f}%",
                'score': best_subject[1]['score']
            })
        
        # éœ€è¦å…³æ³¨çš„å­¦ç§‘
        if snapshot.subject_performance:
            weak_subject = min(snapshot.subject_performance.items(), key=lambda x: x[1]['score'])
            if weak_subject[1]['score'] < 60:
                insights.append({
                    'type': 'weakness',
                    'title': 'éœ€è¦å…³æ³¨',
                    'content': f"{weak_subject[0]}éœ€è¦æ›´å¤šç»ƒä¹ ï¼Œå½“å‰å‡†ç¡®ç‡ä¸º{weak_subject[1]['accuracy']:.1f}%",
                    'score': weak_subject[1]['score']
                })
        
        # å­¦ä¹ ä¹ æƒ¯æ´å¯Ÿ
        if snapshot.engagement_metrics:
            engagement_rate = snapshot.engagement_metrics.get('engagement_rate', 0)
            if engagement_rate > 80:
                insights.append({
                    'type': 'habit',
                    'title': 'å­¦ä¹ ä¹ æƒ¯',
                    'content': f"æ‚¨çš„å­¦ä¹ ä¹ æƒ¯å¾ˆå¥½ï¼Œ{engagement_rate:.1f}%çš„æ—¶é—´éƒ½åœ¨å­¦ä¹ ",
                    'score': engagement_rate
                })
            elif engagement_rate < 50:
                insights.append({
                    'type': 'habit',
                    'title': 'å­¦ä¹ ä¹ æƒ¯',
                    'content': f"å»ºè®®ä¿æŒæ›´è§„å¾‹çš„å­¦ä¹ ä¹ æƒ¯ï¼Œå½“å‰å­¦ä¹ é¢‘ç‡ä¸º{engagement_rate:.1f}%",
                    'score': engagement_rate
                })
        
        return insights
    
    def _prepare_performance_data(self, snapshot: PerformanceSnapshot) -> Dict:
        """å‡†å¤‡è¡¨ç°æ•°æ®"""
        return {
            'overall_score': snapshot.overall_score,
            'learning_efficiency': snapshot.learning_efficiency,
            'knowledge_growth': snapshot.knowledge_growth,
            'skill_improvement': snapshot.skill_improvement,
            'time_metrics': snapshot.time_metrics,
            'accuracy_metrics': snapshot.accuracy_metrics,
            'progress_metrics': snapshot.progress_metrics,
            'engagement_metrics': snapshot.engagement_metrics,
            'subject_performance': snapshot.subject_performance
        }
    
    def _generate_trend_analysis(self, user_id: int, current_snapshot: PerformanceSnapshot) -> Dict:
        """ç”Ÿæˆè¶‹åŠ¿åˆ†æ"""
        # è·å–å†å²å¿«ç…§
        historical_snapshots = db.session.query(PerformanceSnapshot).filter(
            PerformanceSnapshot.user_id == user_id,
            PerformanceSnapshot.id != current_snapshot.id
        ).order_by(PerformanceSnapshot.snapshot_date.desc()).limit(5).all()
        
        if not historical_snapshots:
            return {'trend': 'insufficient_data', 'description': 'æ•°æ®ä¸è¶³ï¼Œæ— æ³•è¿›è¡Œè¶‹åŠ¿åˆ†æ'}
        
        # åˆ†ææ•´ä½“è¶‹åŠ¿
        scores = [current_snapshot.overall_score] + [s.overall_score for s in historical_snapshots]
        scores.reverse()  # æŒ‰æ—¶é—´é¡ºåºæ’åˆ—
        
        if len(scores) >= 3:
            recent_trend = scores[-1] - scores[-3]
            if recent_trend > 5:
                trend = 'improving'
                description = 'æ‚¨çš„å­¦ä¹ è¡¨ç°å‘ˆä¸Šå‡è¶‹åŠ¿ï¼Œç»§ç»­ä¿æŒï¼'
            elif recent_trend < -5:
                trend = 'declining'
                description = 'æœ€è¿‘è¡¨ç°æœ‰æ‰€ä¸‹é™ï¼Œå»ºè®®è°ƒæ•´å­¦ä¹ ç­–ç•¥ã€‚'
            else:
                trend = 'stable'
                description = 'æ‚¨çš„è¡¨ç°ä¿æŒç¨³å®šã€‚'
        else:
            trend = 'stable'
            description = 'è¡¨ç°åŸºæœ¬ç¨³å®šã€‚'
        
        return {
            'trend': trend,
            'description': description,
            'historical_scores': scores,
            'improvement_rate': current_snapshot.improvement_rate
        }
    
    def _identify_achievements(self, snapshot: PerformanceSnapshot) -> List[Dict]:
        """è¯†åˆ«æˆå°±å’Œäº®ç‚¹"""
        achievements = []
        
        # ç»¼åˆå¾—åˆ†æˆå°±
        if snapshot.overall_score >= 90:
            achievements.append({
                'type': 'score',
                'title': 'å­¦éœ¸è¡¨ç°',
                'description': f'ç»¼åˆå¾—åˆ†è¾¾åˆ°{snapshot.overall_score:.1f}åˆ†ï¼Œè¡¨ç°ä¼˜å¼‚ï¼',
                'icon': 'ğŸ†'
            })
        elif snapshot.overall_score >= 80:
            achievements.append({
                'type': 'score',
                'title': 'ä¼˜ç§€è¡¨ç°',
                'description': f'ç»¼åˆå¾—åˆ†{snapshot.overall_score:.1f}åˆ†ï¼Œè¡¨ç°è‰¯å¥½ï¼',
                'icon': 'â­'
            })
        
        # å­¦ä¹ æ•ˆç‡æˆå°±
        if snapshot.learning_efficiency > 0.8:
            achievements.append({
                'type': 'efficiency',
                'title': 'é«˜æ•ˆå­¦ä¹ ',
                'description': 'å­¦ä¹ æ•ˆç‡å¾ˆé«˜ï¼Œèƒ½å¤Ÿå¿«é€ŸæŒæ¡çŸ¥è¯†ç‚¹',
                'icon': 'âš¡'
            })
        
        # çŸ¥è¯†å¢é•¿æˆå°±
        if snapshot.knowledge_growth > 0.2:
            achievements.append({
                'type': 'growth',
                'title': 'å¿«é€Ÿè¿›æ­¥',
                'description': 'çŸ¥è¯†æŒæ¡åº¦æ˜¾è‘—æå‡',
                'icon': 'ğŸ“ˆ'
            })
        
        # å­¦ç§‘è¡¨ç°æˆå°±
        if snapshot.subject_performance:
            excellent_subjects = [name for name, perf in snapshot.subject_performance.items() if perf['accuracy'] >= 90]
            if excellent_subjects:
                achievements.append({
                    'type': 'subject',
                    'title': 'å­¦ç§‘ä¸“å®¶',
                    'description': f'åœ¨{"ã€".join(excellent_subjects)}æ–¹é¢è¡¨ç°å“è¶Š',
                    'icon': 'ğŸ¯'
                })
        
        # åšæŒå­¦ä¹ æˆå°±
        if snapshot.engagement_metrics and snapshot.engagement_metrics.get('engagement_rate', 0) > 85:
            achievements.append({
                'type': 'persistence',
                'title': 'åšæŒä¸æ‡ˆ',
                'description': 'ä¿æŒäº†å¾ˆå¥½çš„å­¦ä¹ ä¹ æƒ¯å’Œé¢‘ç‡',
                'icon': 'ğŸ’ª'
            })
        
        return achievements
    
    def _identify_improvement_areas(self, snapshot: PerformanceSnapshot) -> List[Dict]:
        """è¯†åˆ«éœ€è¦æ”¹è¿›çš„é¢†åŸŸ"""
        areas = []
        
        # å­¦ç§‘è–„å¼±ç‚¹
        if snapshot.subject_performance:
            weak_subjects = [(name, perf) for name, perf in snapshot.subject_performance.items() if perf['accuracy'] < 70]
            for subject_name, perf in weak_subjects:
                areas.append({
                    'type': 'subject_weakness',
                    'title': f'{subject_name}éœ€è¦åŠ å¼º',
                    'description': f'å½“å‰å‡†ç¡®ç‡{perf["accuracy"]:.1f}%ï¼Œå»ºè®®å¢åŠ ç»ƒä¹ ',
                    'priority': 'high' if perf['accuracy'] < 50 else 'medium',
                    'current_score': perf['accuracy'],
                    'target_score': 80
                })
        
        # å­¦ä¹ æ•ˆç‡
        if snapshot.learning_efficiency < 0.5:
            areas.append({
                'type': 'efficiency',
                'title': 'å­¦ä¹ æ•ˆç‡æœ‰å¾…æé«˜',
                'description': 'å»ºè®®ä¼˜åŒ–å­¦ä¹ æ–¹æ³•ï¼Œæé«˜å•ä½æ—¶é—´çš„å­¦ä¹ æ•ˆæœ',
                'priority': 'medium',
                'suggestions': ['åˆ¶å®šå­¦ä¹ è®¡åˆ’', 'ä½¿ç”¨ç•ªèŒ„å·¥ä½œæ³•', 'å‡å°‘å¹²æ‰°å› ç´ ']
            })
        
        # å­¦ä¹ é¢‘ç‡
        if snapshot.engagement_metrics and snapshot.engagement_metrics.get('engagement_rate', 0) < 60:
            areas.append({
                'type': 'frequency',
                'title': 'å­¦ä¹ é¢‘ç‡éœ€è¦æå‡',
                'description': 'å»ºè®®ä¿æŒæ›´è§„å¾‹çš„å­¦ä¹ ä¹ æƒ¯',
                'priority': 'high',
                'current_rate': snapshot.engagement_metrics.get('engagement_rate', 0),
                'target_rate': 80
            })
        
        # çŸ¥è¯†å·©å›º
        if snapshot.knowledge_growth < 0.1:
            areas.append({
                'type': 'consolidation',
                'title': 'çŸ¥è¯†å·©å›ºä¸è¶³',
                'description': 'å»ºè®®åŠ å¼ºå¤ä¹ ï¼Œå·©å›ºå·²å­¦çŸ¥è¯†',
                'priority': 'medium',
                'suggestions': ['å®šæœŸå¤ä¹ ', 'ä½¿ç”¨è®°å¿†å¡ç‰‡', 'åšé”™é¢˜é›†']
            })
        
        return areas
    
    def _generate_recommendations(self, snapshot: PerformanceSnapshot) -> List[Dict]:
        """ç”Ÿæˆå»ºè®®å’Œè¡ŒåŠ¨è®¡åˆ’"""
        recommendations = []
        
        # åŸºäºç»¼åˆå¾—åˆ†çš„å»ºè®®
        if snapshot.overall_score < 60:
            recommendations.append({
                'category': 'overall',
                'priority': 'high',
                'title': 'å…¨é¢æå‡å­¦ä¹ æ•ˆæœ',
                'description': 'å½“å‰ç»¼åˆè¡¨ç°éœ€è¦å…¨é¢æ”¹è¿›',
                'actions': [
                    'åˆ¶å®šè¯¦ç»†çš„å­¦ä¹ è®¡åˆ’',
                    'æ¯æ—¥è‡³å°‘å­¦ä¹ 2å°æ—¶',
                    'é‡ç‚¹æ”»å…‹è–„å¼±å­¦ç§‘',
                    'å¯»æ±‚è€å¸ˆæˆ–åŒå­¦å¸®åŠ©'
                ],
                'timeline': '2-4å‘¨'
            })
        elif snapshot.overall_score < 80:
            recommendations.append({
                'category': 'improvement',
                'priority': 'medium',
                'title': 'ç¨³æ­¥æå‡å­¦ä¹ æ°´å¹³',
                'description': 'åœ¨ç°æœ‰åŸºç¡€ä¸Šè¿›ä¸€æ­¥æé«˜',
                'actions': [
                    'é’ˆå¯¹æ€§ç»ƒä¹ è–„å¼±çŸ¥è¯†ç‚¹',
                    'æé«˜ç­”é¢˜å‡†ç¡®ç‡',
                    'å¢åŠ å­¦ä¹ æ—¶é—´æŠ•å…¥',
                    'å®šæœŸè‡ªæˆ‘æµ‹è¯•'
                ],
                'timeline': '1-2å‘¨'
            })
        
        # åŸºäºå­¦ç§‘è¡¨ç°çš„å»ºè®®
        if snapshot.subject_performance:
            weak_subjects = [name for name, perf in snapshot.subject_performance.items() if perf['accuracy'] < 70]
            if weak_subjects:
                recommendations.append({
                    'category': 'subject',
                    'priority': 'high',
                    'title': f'é‡ç‚¹æå‡{"ã€".join(weak_subjects[:2])}',
                    'description': 'è¿™äº›å­¦ç§‘éœ€è¦é¢å¤–å…³æ³¨',
                    'actions': [
                        'æ¯æ—¥ä¸“é—¨ç»ƒä¹ 30åˆ†é’Ÿ',
                        'æ•´ç†é”™é¢˜å’ŒçŸ¥è¯†ç‚¹',
                        'å¯»æ‰¾ç›¸å…³å­¦ä¹ èµ„æº',
                        'ä¸è€å¸ˆè®¨è®ºå­¦ä¹ æ–¹æ³•'
                    ],
                    'timeline': 'æŒç»­è¿›è¡Œ'
                })
        
        # åŸºäºå­¦ä¹ ä¹ æƒ¯çš„å»ºè®®
        if snapshot.engagement_metrics and snapshot.engagement_metrics.get('engagement_rate', 0) < 70:
            recommendations.append({
                'category': 'habit',
                'priority': 'medium',
                'title': 'å»ºç«‹è§„å¾‹å­¦ä¹ ä¹ æƒ¯',
                'description': 'æé«˜å­¦ä¹ é¢‘ç‡å’ŒæŒç»­æ€§',
                'actions': [
                    'è®¾å®šå›ºå®šå­¦ä¹ æ—¶é—´',
                    'ä½¿ç”¨å­¦ä¹ æé†’åŠŸèƒ½',
                    'åˆ¶å®šæ¯æ—¥å­¦ä¹ ç›®æ ‡',
                    'è®°å½•å­¦ä¹ è¿›åº¦'
                ],
                'timeline': '1å‘¨å†…å»ºç«‹'
            })
        
        # åŸºäºå­¦ä¹ æ•ˆç‡çš„å»ºè®®
        if snapshot.learning_efficiency < 0.6:
            recommendations.append({
                'category': 'efficiency',
                'priority': 'medium',
                'title': 'ä¼˜åŒ–å­¦ä¹ æ–¹æ³•',
                'description': 'æé«˜å­¦ä¹ æ•ˆç‡å’Œæ•ˆæœ',
                'actions': [
                    'å°è¯•ä¸åŒçš„å­¦ä¹ æŠ€å·§',
                    'å‡å°‘å­¦ä¹ æ—¶çš„å¹²æ‰°',
                    'åˆç†å®‰æ’ä¼‘æ¯æ—¶é—´',
                    'ä½¿ç”¨æ€ç»´å¯¼å›¾ç­‰å·¥å…·'
                ],
                'timeline': 'é€æ­¥è°ƒæ•´'
            })
        
        return recommendations
    
    def _prepare_charts_data(self, snapshot: PerformanceSnapshot) -> Dict:
        """å‡†å¤‡å›¾è¡¨æ•°æ®"""
        charts_data = {}
        
        # ç»¼åˆè¡¨ç°é›·è¾¾å›¾
        charts_data['performance_radar'] = {
            'type': 'radar',
            'title': 'ç»¼åˆè¡¨ç°é›·è¾¾å›¾',
            'data': {
                'labels': ['ç»¼åˆå¾—åˆ†', 'å­¦ä¹ æ•ˆç‡', 'çŸ¥è¯†å¢é•¿', 'æŠ€èƒ½æå‡'],
                'values': [
                    snapshot.overall_score,
                    snapshot.learning_efficiency * 100,
                    snapshot.knowledge_growth * 100,
                    snapshot.skill_improvement * 100
                ]
            }
        }
        
        # å­¦ç§‘è¡¨ç°æŸ±çŠ¶å›¾
        if snapshot.subject_performance:
            subjects = list(snapshot.subject_performance.keys())
            accuracies = [snapshot.subject_performance[s]['accuracy'] for s in subjects]
            
            charts_data['subject_performance'] = {
                'type': 'bar',
                'title': 'å„å­¦ç§‘å‡†ç¡®ç‡',
                'data': {
                    'labels': subjects,
                    'values': accuracies
                }
            }
        
        # æ—¶é—´åˆ†é…é¥¼å›¾
        if snapshot.time_metrics:
            time_data = {}
            for metric_name, metric_info in snapshot.time_metrics.items():
                if 'å­¦ä¹ æ—¶é•¿' in metric_name and metric_name != 'æ€»å­¦ä¹ æ—¶é•¿':
                    subject = metric_name.replace('å­¦ä¹ æ—¶é•¿', '')
                    time_data[subject] = metric_info['value']
            
            if time_data:
                charts_data['time_allocation'] = {
                    'type': 'pie',
                    'title': 'å­¦ä¹ æ—¶é—´åˆ†é…',
                    'data': {
                        'labels': list(time_data.keys()),
                        'values': list(time_data.values())
                    }
                }
        
        return charts_data
    
    # ==================== ç›®æ ‡è¿½è¸ª ====================
    
    def create_learning_goal(self, user_id: int, tenant_id: int, goal_data: Dict) -> Optional[GoalTracking]:
        """
        åˆ›å»ºå­¦ä¹ ç›®æ ‡
        
        Args:
            user_id: ç”¨æˆ·ID
            tenant_id: ç§Ÿæˆ·ID
            goal_data: ç›®æ ‡æ•°æ®
            
        Returns:
            ç›®æ ‡è¿½è¸ªå¯¹è±¡
        """
        try:
            goal = GoalTracking(
                user_id=user_id,
                tenant_id=tenant_id,
                goal_title=goal_data['goal_title'],
                goal_description=goal_data.get('goal_description'),
                goal_type=goal_data['goal_type'],
                target_value=goal_data['target_value'],
                unit=goal_data.get('unit'),
                start_date=goal_data['start_date'],
                target_date=goal_data['target_date'],
                subject_id=goal_data.get('subject_id'),
                knowledge_point_id=goal_data.get('knowledge_point_id'),
                milestones=goal_data.get('milestones', [])
            )
            
            db.session.add(goal)
            db.session.commit()
            
            return goal
            
        except Exception as e:
            db.session.rollback()
            logger.error(f"åˆ›å»ºå­¦ä¹ ç›®æ ‡å¤±è´¥: {str(e)}")
            return None
    
    def update_goal_progress(self, goal_id: int, new_value: float) -> bool:
        """
        æ›´æ–°ç›®æ ‡è¿›åº¦
        
        Args:
            goal_id: ç›®æ ‡ID
            new_value: æ–°çš„è¿›åº¦å€¼
            
        Returns:
            æ˜¯å¦æ›´æ–°æˆåŠŸ
        """
        try:
            goal = db.session.query(GoalTracking).filter(GoalTracking.id == goal_id).first()
            if not goal:
                return False
            
            goal.update_progress(new_value)
            db.session.commit()
            
            return True
            
        except Exception as e:
            db.session.rollback()
            logger.error(f"æ›´æ–°ç›®æ ‡è¿›åº¦å¤±è´¥: {str(e)}")
            return False
    
    def get_user_goals(self, user_id: int, is_active: Optional[bool] = None) -> List[GoalTracking]:
        """
        è·å–ç”¨æˆ·ç›®æ ‡åˆ—è¡¨
        
        Args:
            user_id: ç”¨æˆ·ID
            is_active: æ˜¯å¦åªè·å–æ´»è·ƒç›®æ ‡
            
        Returns:
            ç›®æ ‡åˆ—è¡¨
        """
        query = db.session.query(GoalTracking).filter(GoalTracking.user_id == user_id)
        
        if is_active is not None:
            query = query.filter(GoalTracking.is_active == is_active)
        
        return query.order_by(GoalTracking.target_date.asc()).all()
    
    # ==================== åé¦ˆç®¡ç† ====================
    
    def create_feedback(self, user_id: int, tenant_id: int, feedback_data: Dict) -> Optional[FeedbackRecord]:
        """
        åˆ›å»ºåé¦ˆè®°å½•
        
        Args:
            user_id: ç”¨æˆ·ID
            tenant_id: ç§Ÿæˆ·ID
            feedback_data: åé¦ˆæ•°æ®
            
        Returns:
            åé¦ˆè®°å½•å¯¹è±¡
        """
        try:
            feedback = FeedbackRecord(
                user_id=user_id,
                tenant_id=tenant_id,
                feedback_type=feedback_data['feedback_type'],
                feedback_category=feedback_data['feedback_category'],
                feedback_title=feedback_data['feedback_title'],
                feedback_content=feedback_data['feedback_content'],
                source_type=feedback_data['source_type'],
                source_id=feedback_data.get('source_id'),
                priority=feedback_data.get('priority', 'medium'),
                importance_score=feedback_data.get('importance_score', 0.5),
                related_subject_id=feedback_data.get('related_subject_id'),
                related_report_id=feedback_data.get('related_report_id')
            )
            
            db.session.add(feedback)
            db.session.commit()
            
            return feedback
            
        except Exception as e:
            db.session.rollback()
            logger.error(f"åˆ›å»ºåé¦ˆè®°å½•å¤±è´¥: {str(e)}")
            return None
    
    def get_user_feedback(self, user_id: int, is_read: Optional[bool] = None, 
                         priority: Optional[str] = None, limit: int = 50) -> List[FeedbackRecord]:
        """
        è·å–ç”¨æˆ·åé¦ˆåˆ—è¡¨
        
        Args:
            user_id: ç”¨æˆ·ID
            is_read: æ˜¯å¦å·²è¯»
            priority: ä¼˜å…ˆçº§è¿‡æ»¤
            limit: è¿”å›æ•°é‡é™åˆ¶
            
        Returns:
            åé¦ˆè®°å½•åˆ—è¡¨
        """
        query = db.session.query(FeedbackRecord).filter(FeedbackRecord.user_id == user_id)
        
        if is_read is not None:
            query = query.filter(FeedbackRecord.is_read == is_read)
        
        if priority:
            query = query.filter(FeedbackRecord.priority == priority)
        
        return query.order_by(FeedbackRecord.created_time.desc()).limit(limit).all()
    
    def mark_feedback_as_read(self, feedback_id: int) -> bool:
        """
        æ ‡è®°åé¦ˆä¸ºå·²è¯»
        
        Args:
            feedback_id: åé¦ˆID
            
        Returns:
            æ˜¯å¦æ ‡è®°æˆåŠŸ
        """
        try:
            feedback = db.session.query(FeedbackRecord).filter(FeedbackRecord.id == feedback_id).first()
            if not feedback:
                return False
            
            feedback.mark_as_read()
            db.session.commit()
            
            return True
            
        except Exception as e:
            db.session.rollback()
            logger.error(f"æ ‡è®°åé¦ˆå·²è¯»å¤±è´¥: {str(e)}")
            return False
    
    # ==================== æ•°æ®ç»Ÿè®¡ ====================
    
    def get_learning_statistics(self, user_id: int, period_start: datetime, period_end: datetime) -> Dict:
        """
        è·å–å­¦ä¹ ç»Ÿè®¡æ•°æ®
        
        Args:
            user_id: ç”¨æˆ·ID
            period_start: ç»Ÿè®¡å¼€å§‹æ—¶é—´
            period_end: ç»Ÿè®¡ç»“æŸæ—¶é—´
            
        Returns:
            ç»Ÿè®¡æ•°æ®å­—å…¸
        """
        try:
            stats = {}
            
            # åŸºç¡€ç»Ÿè®¡
            stats['basic'] = self._get_basic_statistics(user_id, period_start, period_end)
            
            # å­¦ä¹ æ—¶é—´ç»Ÿè®¡
            stats['time'] = self._get_time_statistics(user_id, period_start, period_end)
            
            # ç­”é¢˜ç»Ÿè®¡
            stats['questions'] = self._get_question_statistics(user_id, period_start, period_end)
            
            # å‡†ç¡®ç‡ç»Ÿè®¡
            stats['accuracy'] = self._get_accuracy_statistics(user_id, period_start, period_end)
            
            # è¿›åº¦ç»Ÿè®¡
            stats['progress'] = self._get_progress_statistics(user_id, period_start, period_end)
            
            # ç›®æ ‡å®Œæˆç»Ÿè®¡
            stats['goals'] = self._get_goal_statistics(user_id, period_start, period_end)
            
            return stats
            
        except Exception as e:
            logger.error(f"è·å–å­¦ä¹ ç»Ÿè®¡å¤±è´¥: {str(e)}")
            return {}
    
    def _get_basic_statistics(self, user_id: int, period_start: datetime, period_end: datetime) -> Dict:
        """è·å–åŸºç¡€ç»Ÿè®¡"""
        # å­¦ä¹ å¤©æ•°
        learning_days = db.session.query(func.count(func.distinct(func.date(LearningSession.start_time)))).filter(
            LearningSession.user_id == user_id,
            LearningSession.start_time >= period_start,
            LearningSession.start_time <= period_end
        ).scalar() or 0
        
        # å­¦ä¹ ä¼šè¯æ•°
        session_count = db.session.query(func.count(LearningSession.id)).filter(
            LearningSession.user_id == user_id,
            LearningSession.start_time >= period_start,
            LearningSession.start_time <= period_end
        ).scalar() or 0
        
        # æ€»å­¦ä¹ æ—¶é•¿
        total_time = db.session.query(func.sum(LearningSession.duration_minutes)).filter(
            LearningSession.user_id == user_id,
            LearningSession.start_time >= period_start,
            LearningSession.start_time <= period_end
        ).scalar() or 0
        
        return {
            'learning_days': learning_days,
            'session_count': session_count,
            'total_time_minutes': total_time,
            'avg_session_time': total_time / session_count if session_count > 0 else 0
        }
    
    def _get_time_statistics(self, user_id: int, period_start: datetime, period_end: datetime) -> Dict:
        """è·å–æ—¶é—´ç»Ÿè®¡"""
        # æŒ‰å­¦ç§‘ç»Ÿè®¡æ—¶é—´
        subject_times = db.session.query(
            Subject.name,
            func.sum(LearningSession.duration_minutes)
        ).join(LearningSession).filter(
            LearningSession.user_id == user_id,
            LearningSession.start_time >= period_start,
            LearningSession.start_time <= period_end
        ).group_by(Subject.id).all()
        
        # æŒ‰æ—¥æœŸç»Ÿè®¡æ—¶é—´
        daily_times = db.session.query(
            func.date(LearningSession.start_time).label('date'),
            func.sum(LearningSession.duration_minutes).label('total_time')
        ).filter(
            LearningSession.user_id == user_id,
            LearningSession.start_time >= period_start,
            LearningSession.start_time <= period_end
        ).group_by(func.date(LearningSession.start_time)).all()
        
        return {
            'subject_distribution': {name: time for name, time in subject_times},
            'daily_distribution': {str(date): time for date, time in daily_times}
        }
    
    def _get_question_statistics(self, user_id: int, period_start: datetime, period_end: datetime) -> Dict:
        """è·å–ç­”é¢˜ç»Ÿè®¡"""
        # æ€»ç­”é¢˜æ•°
        total_questions = db.session.query(func.count(UserAnswer.id)).filter(
            UserAnswer.user_id == user_id,
            UserAnswer.created_time >= period_start,
            UserAnswer.created_time <= period_end
        ).scalar() or 0
        
        # æŒ‰éš¾åº¦ç»Ÿè®¡
        difficulty_stats = db.session.query(
            Question.difficulty_level,
            func.count(UserAnswer.id)
        ).join(UserAnswer).filter(
            UserAnswer.user_id == user_id,
            UserAnswer.created_time >= period_start,
            UserAnswer.created_time <= period_end
        ).group_by(Question.difficulty_level).all()
        
        # æŒ‰å­¦ç§‘ç»Ÿè®¡
        subject_stats = db.session.query(
            Subject.name,
            func.count(UserAnswer.id)
        ).join(Question).join(UserAnswer).filter(
            UserAnswer.user_id == user_id,
            UserAnswer.created_time >= period_start,
            UserAnswer.created_time <= period_end
        ).group_by(Subject.id).all()
        
        return {
            'total_questions': total_questions,
            'difficulty_distribution': {level: count for level, count in difficulty_stats},
            'subject_distribution': {name: count for name, count in subject_stats}
        }
    
    def _get_accuracy_statistics(self, user_id: int, period_start: datetime, period_end: datetime) -> Dict:
        """è·å–å‡†ç¡®ç‡ç»Ÿè®¡"""
        # æ€»ä½“å‡†ç¡®ç‡
        total_answers = db.session.query(func.count(UserAnswer.id)).filter(
            UserAnswer.user_id == user_id,
            UserAnswer.created_time >= period_start,
            UserAnswer.created_time <= period_end
        ).scalar() or 0
        
        correct_answers = db.session.query(func.count(UserAnswer.id)).filter(
            UserAnswer.user_id == user_id,
            UserAnswer.is_correct == True,
            UserAnswer.created_time >= period_start,
            UserAnswer.created_time <= period_end
        ).scalar() or 0
        
        overall_accuracy = (correct_answers / total_answers * 100) if total_answers > 0 else 0
        
        # æŒ‰å­¦ç§‘ç»Ÿè®¡å‡†ç¡®ç‡
        subject_accuracy = db.session.query(
            Subject.name,
            func.count(UserAnswer.id).label('total'),
            func.sum(func.cast(UserAnswer.is_correct, db.Integer)).label('correct')
        ).join(Question).join(UserAnswer).filter(
            UserAnswer.user_id == user_id,
            UserAnswer.created_time >= period_start,
            UserAnswer.created_time <= period_end
        ).group_by(Subject.id).all()
        
        return {
            'overall_accuracy': overall_accuracy,
            'subject_accuracy': {name: (correct/total*100 if total > 0 else 0) for name, total, correct in subject_accuracy}
        }
    
    def _get_progress_statistics(self, user_id: int, period_start: datetime, period_end: datetime) -> Dict:
        """è·å–è¿›åº¦ç»Ÿè®¡"""
        # çŸ¥è¯†ç‚¹æŒæ¡æƒ…å†µ
        progress_records = db.session.query(LearningProgress).filter(
            LearningProgress.user_id == user_id,
            LearningProgress.updated_time >= period_start,
            LearningProgress.updated_time <= period_end
        ).all()
        
        if not progress_records:
            return {'avg_mastery': 0, 'mastery_distribution': {}}
        
        avg_mastery = statistics.mean([p.mastery_level for p in progress_records])
        
        # æŒæ¡åº¦åˆ†å¸ƒ
        mastery_ranges = {
            'ä¼˜ç§€(90-100%)': 0,
            'è‰¯å¥½(80-89%)': 0,
            'ä¸€èˆ¬(70-79%)': 0,
            'å¾…æé«˜(60-69%)': 0,
            'éœ€åŠ å¼º(<60%)': 0
        }
        
        for progress in progress_records:
            mastery_percent = progress.mastery_level * 100
            if mastery_percent >= 90:
                mastery_ranges['ä¼˜ç§€(90-100%)'] += 1
            elif mastery_percent >= 80:
                mastery_ranges['è‰¯å¥½(80-89%)'] += 1
            elif mastery_percent >= 70:
                mastery_ranges['ä¸€èˆ¬(70-79%)'] += 1
            elif mastery_percent >= 60:
                mastery_ranges['å¾…æé«˜(60-69%)'] += 1
            else:
                mastery_ranges['éœ€åŠ å¼º(<60%)'] += 1
        
        return {
            'avg_mastery': avg_mastery * 100,
            'mastery_distribution': mastery_ranges
        }
    
    def _get_goal_statistics(self, user_id: int, period_start: datetime, period_end: datetime) -> Dict:
        """è·å–ç›®æ ‡ç»Ÿè®¡"""
        # è¯¥æ—¶æœŸå†…çš„ç›®æ ‡
        goals = db.session.query(GoalTracking).filter(
            GoalTracking.user_id == user_id,
            or_(
                and_(GoalTracking.start_date >= period_start, GoalTracking.start_date <= period_end),
                and_(GoalTracking.target_date >= period_start, GoalTracking.target_date <= period_end),
                and_(GoalTracking.start_date <= period_start, GoalTracking.target_date >= period_end)
            )
        ).all()
        
        if not goals:
            return {'total_goals': 0, 'completed_goals': 0, 'completion_rate': 0}
        
        completed_goals = sum(1 for goal in goals if goal.is_completed)
        completion_rate = (completed_goals / len(goals) * 100) if goals else 0
        
        return {
            'total_goals': len(goals),
            'completed_goals': completed_goals,
            'completion_rate': completion_rate,
            'active_goals': sum(1 for goal in goals if goal.is_active and not goal.is_completed)
        }
    
    # ==================== è¾…åŠ©æ–¹æ³• ====================
    
    def get_user_metrics(self, user_id: int, metric_type: Optional[str] = None, 
                        period_start: Optional[datetime] = None, period_end: Optional[datetime] = None,
                        subject_id: Optional[int] = None, limit: int = 100) -> List[LearningMetric]:
        """
        è·å–ç”¨æˆ·æŒ‡æ ‡æ•°æ®
        
        Args:
            user_id: ç”¨æˆ·ID
            metric_type: æŒ‡æ ‡ç±»å‹
            period_start: å¼€å§‹æ—¶é—´
            period_end: ç»“æŸæ—¶é—´
            subject_id: å­¦ç§‘ID
            limit: è¿”å›æ•°é‡é™åˆ¶
            
        Returns:
            æŒ‡æ ‡è®°å½•åˆ—è¡¨
        """
        query = db.session.query(LearningMetric).filter(LearningMetric.user_id == user_id)
        
        if metric_type:
            query = query.filter(LearningMetric.metric_type == metric_type)
        
        if period_start:
            query = query.filter(LearningMetric.recorded_time >= period_start)
        
        if period_end:
            query = query.filter(LearningMetric.recorded_time <= period_end)
        
        if subject_id:
            query = query.filter(LearningMetric.subject_id == subject_id)
        
        return query.order_by(LearningMetric.recorded_time.desc()).limit(limit).all()
    
    def get_user_snapshots(self, user_id: int, snapshot_type: Optional[str] = None,
                          period_start: Optional[datetime] = None, period_end: Optional[datetime] = None,
                          limit: int = 50) -> List[PerformanceSnapshot]:
        """
        è·å–ç”¨æˆ·æ€§èƒ½å¿«ç…§åˆ—è¡¨
        
        Args:
            user_id: ç”¨æˆ·ID
            snapshot_type: å¿«ç…§ç±»å‹
            period_start: å¼€å§‹æ—¶é—´
            period_end: ç»“æŸæ—¶é—´
            limit: è¿”å›æ•°é‡é™åˆ¶
            
        Returns:
            å¿«ç…§è®°å½•åˆ—è¡¨
        """
        query = db.session.query(PerformanceSnapshot).filter(PerformanceSnapshot.user_id == user_id)
        
        if snapshot_type:
            query = query.filter(PerformanceSnapshot.snapshot_type == snapshot_type)
        
        if period_start:
            query = query.filter(PerformanceSnapshot.period_start >= period_start)
        
        if period_end:
            query = query.filter(PerformanceSnapshot.period_end <= period_end)
        
        return query.order_by(PerformanceSnapshot.created_time.desc()).limit(limit).all()
    
    def get_snapshot_by_id(self, snapshot_id: int, user_id: int) -> Optional[PerformanceSnapshot]:
        """
        æ ¹æ®IDè·å–å¿«ç…§è¯¦æƒ…
        
        Args:
            snapshot_id: å¿«ç…§ID
            user_id: ç”¨æˆ·ID
            
        Returns:
            å¿«ç…§å¯¹è±¡
        """
        return db.session.query(PerformanceSnapshot).filter(
            PerformanceSnapshot.id == snapshot_id,
            PerformanceSnapshot.user_id == user_id
        ).first()
    
    def get_user_reports(self, user_id: int, report_type: Optional[str] = None,
                        period_start: Optional[datetime] = None, period_end: Optional[datetime] = None,
                        limit: int = 50) -> List[LearningReport]:
        """
        è·å–ç”¨æˆ·å­¦ä¹ æŠ¥å‘Šåˆ—è¡¨
        
        Args:
            user_id: ç”¨æˆ·ID
            report_type: æŠ¥å‘Šç±»å‹
            period_start: å¼€å§‹æ—¶é—´
            period_end: ç»“æŸæ—¶é—´
            limit: è¿”å›æ•°é‡é™åˆ¶
            
        Returns:
            æŠ¥å‘Šè®°å½•åˆ—è¡¨
        """
        query = db.session.query(LearningReport).filter(LearningReport.user_id == user_id)
        
        if report_type:
            query = query.filter(LearningReport.report_type == report_type)
        
        if period_start:
            query = query.filter(LearningReport.period_start >= period_start)
        
        if period_end:
            query = query.filter(LearningReport.period_end <= period_end)
        
        return query.order_by(LearningReport.generated_time.desc()).limit(limit).all()
    
    def get_report_by_id(self, report_id: int, user_id: int) -> Optional[LearningReport]:
        """
        æ ¹æ®IDè·å–æŠ¥å‘Šè¯¦æƒ…
        
        Args:
            report_id: æŠ¥å‘ŠID
            user_id: ç”¨æˆ·ID
            
        Returns:
            æŠ¥å‘Šå¯¹è±¡
        """
        return db.session.query(LearningReport).filter(
            LearningReport.id == report_id,
            LearningReport.user_id == user_id
        ).first()
    
    def update_goal_progress(self, goal_id: int, user_id: int, current_value: float, progress_note: str = '') -> bool:
        """
        æ›´æ–°ç›®æ ‡è¿›åº¦ï¼ˆé‡è½½æ–¹æ³•ï¼Œå¢åŠ ç”¨æˆ·éªŒè¯ï¼‰
        
        Args:
            goal_id: ç›®æ ‡ID
            user_id: ç”¨æˆ·ID
            current_value: å½“å‰å€¼
            progress_note: è¿›åº¦å¤‡æ³¨
            
        Returns:
            æ˜¯å¦æ›´æ–°æˆåŠŸ
        """
        try:
            goal = db.session.query(GoalTracking).filter(
                GoalTracking.id == goal_id,
                GoalTracking.user_id == user_id
            ).first()
            
            if not goal:
                return False
            
            goal.update_progress(current_value, progress_note)
            db.session.commit()
            
            return True
            
        except Exception as e:
            db.session.rollback()
            logger.error(f"æ›´æ–°ç›®æ ‡è¿›åº¦å¤±è´¥: {str(e)}")
            return False